[
    {
        "instance_id": "hyperium__hyper-3275",
        "code_snippet": "    fn poll_frame(\n        mut self: Pin<&mut Self>,\n        cx: &mut task::Context<'_>,\n    ) -> Poll<Option<Result<Frame<Self::Data>, Self::Error>>> {\n        match self.kind {\n            Kind::Empty => Poll::Ready(None),\n            Kind::Chan {\n                content_length: ref mut len,\n                ref mut data_rx,\n                ref mut want_tx,\n                ref mut trailers_rx,\n            } => {\n                want_tx.send(WANT_READY);\n\n                if !data_rx.is_terminated() {\n                    match ready!(Pin::new(data_rx).poll_next(cx)?) {\n                        Some(chunk) => {\n                            len.sub_if(chunk.len() as u64);\n                            return Poll::Ready(Some(Ok(Frame::data(chunk))));\n                        }\n                        // fall through to trailers\n                        None => (),\n                    }\n                }\n\n                // check trailers after data is terminated\n                match ready!(Pin::new(trailers_rx).poll(cx)) {\n                    Ok(t) => Poll::Ready(Some(Ok(Frame::trailers(t)))),\n                    Err(_) => Poll::Ready(None),\n                }\n            }\n            #[cfg(all(feature = \"http2\", any(feature = \"client\", feature = \"server\")))]\n            Kind::H2 {\n                ref mut data_done,\n                ref ping,\n                recv: ref mut h2,\n                content_length: ref mut len,\n            } => {\n                if !*data_done {\n                    match ready!(h2.poll_data(cx)) {\n                        Some(Ok(bytes)) => {\n                            let _ = h2.flow_control().release_capacity(bytes.len());\n                            len.sub_if(bytes.len() as u64);\n                            ping.record_data(bytes.len());\n                            return Poll::Ready(Some(Ok(Frame::data(bytes))));\n                        }\n                        Some(Err(e)) => return Poll::Ready(Some(Err(crate::Error::new_body(e)))),\n                        None => {\n                            *data_done = true;\n                            // fall through to trailers\n                        }\n                    }\n                }\n\n                // after data, check trailers\n                match ready!(h2.poll_trailers(cx)) {\n                    Ok(t) => {\n                        ping.record_non_data();\n                        Poll::Ready(Ok(t.map(Frame::trailers)).transpose())\n                    }\n                    Err(e) => Poll::Ready(Some(Err(crate::Error::new_h2(e)))),\n                }\n            }\n\n            #[cfg(feature = \"ffi\")]\n            Kind::Ffi(ref mut body) => body.poll_data(cx),\n        }\n    }\n",
        "target_function": "    fn poll_frame(\n        mut self: Pin<&mut Self>,\n        cx: &mut task::Context<'_>,\n    ) -> Poll<Option<Result<Frame<Self::Data>, Self::Error>>> {\n        match self.kind {\n            Kind::Empty => Poll::Ready(None),\n            Kind::Chan {\n                content_length: ref mut len,\n                ref mut data_rx,\n                ref mut want_tx,\n                ref mut trailers_rx,\n            } => {\n                want_tx.send(WANT_READY);\n\n                if !data_rx.is_terminated() {\n                    match ready!(Pin::new(data_rx).poll_next(cx)?) {\n                        Some(chunk) => {\n                            len.sub_if(chunk.len() as u64);\n                            return Poll::Ready(Some(Ok(Frame::data(chunk))));\n                        }\n                        // fall through to trailers\n                        None => (),\n                    }\n                }\n\n                // check trailers after data is terminated\n                match ready!(Pin::new(trailers_rx).poll(cx)) {\n                    Ok(t) => Poll::Ready(Some(Ok(Frame::trailers(t)))),\n                    Err(_) => Poll::Ready(None),\n                }\n            }\n            #[cfg(all(feature = \"http2\", any(feature = \"client\", feature = \"server\")))]\n            Kind::H2 {\n                ref mut data_done,\n                ref ping,\n                recv: ref mut h2,\n                content_length: ref mut len,\n            } => {\n                if !*data_done {\n                    match ready!(h2.poll_data(cx)) {\n                        Some(Ok(bytes)) => {\n                            let _ = h2.flow_control().release_capacity(bytes.len());\n                            len.sub_if(bytes.len() as u64);\n                            ping.record_data(bytes.len());\n                            return Poll::Ready(Some(Ok(Frame::data(bytes))));\n                        }\n                        Some(Err(e)) => return Poll::Ready(Some(Err(crate::Error::new_body(e)))),\n                        None => {\n                            *data_done = true;\n                            // fall through to trailers\n                        }\n                    }\n                }\n\n                // after data, check trailers\n                match ready!(h2.poll_trailers(cx)) {\n                    Ok(t) => {\n                        ping.record_non_data();\n                        Poll::Ready(Ok(t.map(Frame::trailers)).transpose())\n                    }\n                    Err(e) => Poll::Ready(Some(Err(crate::Error::new_h2(e)))),\n                }\n            }\n\n            #[cfg(feature = \"ffi\")]\n            Kind::Ffi(ref mut body) => body.poll_data(cx),\n        }\n    }\n",
        "review_type": "function",
        "repo": "hyperium/hyper",
        "issue_detail": {
            "location": "src/body/incoming.rs: line: 201-208, src/proto/mod.rs: line: 50-57, ",
            "description": "Client: handle `RST_STREAM` with `NO_ERROR` set for the reason\n**Version**\r\n```\r\nhyper = \"0.14.18\"\r\nh2 = \"0.3.13\"\r\n```\r\n\r\n**Platform**\r\n```\r\n> uname -a\r\nLinux <REDACTED> 5.17.5-76051705-generic #202204271406~1651504840~22.04~63e51bd SMP PREEMPT Mon May 2 15: x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\n**Description**\r\nI've found that Google Cloud Storage's API can respond with HTTP/2 `RST_STREAM` frame with `NO_ERROR` set for the reason, which appears to mean \"stop sending the request body and read my response\" according to https://datatracker.ietf.org/doc/html/rfc7540#section-8.1\r\n\r\n> A server can send a complete response prior to the client sending an entire\r\n   request if the response does not depend on any portion of the request\r\n   that has not been sent and received.  When this is true, a server MAY\r\n   request that the client abort transmission of a request without error\r\n   by sending a RST_STREAM with an error code of NO_ERROR after sending\r\n   a complete response (i.e., a frame with the END_STREAM flag).\r\n   Clients MUST NOT discard responses as a result of receiving such a\r\n   RST_STREAM, though clients can always discard responses at their\r\n   discretion for other reasons.\r\n\r\nI believe this is happening in response to a `PutObject` request when the bucket is being rate limited for writes. The server is trying to tell the client to stop sending the request body because it won't be processed, and instead it should immediately read the response to discover the `429 Too Many Requests` error code.\r\n\r\nHowever, Hyper's client implementation appears to just return the `RST_STREAM` message as an error and discards the response instead of handling it, which gives a hilariously confusing error message of:\r\n```\r\nerror reading a body from connection: stream error received: not a result of an error\r\n```\r\n\r\nTo be compliant with the spec, the implementation should stop sending the body and immediately read the response and return it.\r\n\r\nFor context, I'm using the Gcloud Storage API via https://crates.io/crates/aws-sdk-s3 (because the Gcloud Rust SDK doesn't support streaming bodies, but thankfully Gcloud Storage exposes an S3-compatible API), which uses Hyper internally. `aws-sdk-s3` appears to be returning the error from Hyper verbatim, however.\n"
        },
        "branch": "fix-rst-stream-error-for-early-response-h2",
        "file_path": "src/body/incoming.rs,src/proto/mod.rs",
        "language": "rust"
    },
    {
        "instance_id": "serde-rs__serde-2562",
        "code_snippet": "pub fn check(cx: &Ctxt, cont: &mut Container, derive: Derive) {\n    check_default_on_tuple(cx, cont);\n    check_remote_generic(cx, cont);\n    check_getter(cx, cont);\n    check_flatten(cx, cont);\n    check_identifier(cx, cont);\n    check_variant_skip_attrs(cx, cont);\n    check_internal_tag_field_name_conflict(cx, cont);\n    check_adjacent_tag_conflict(cx, cont);\n    check_transparent(cx, cont, derive);\n    check_from_and_try_from(cx, cont);\n}\nfn check_from_and_try_from(cx: &Ctxt, cont: &mut Container) {\n    if cont.attrs.type_from().is_some() && cont.attrs.type_try_from().is_some() {\n        cx.error_spanned_by(\n            cont.original,\n            \"#[serde(from = \\\"...\\\")] and #[serde(try_from = \\\"...\\\")] conflict with each other\",\n        );\n    }\n}\n",
        "target_function": "pub fn check(cx: &Ctxt, cont: &mut Container, derive: Derive) {\n    check_default_on_tuple(cx, cont);\n    check_remote_generic(cx, cont);\n    check_getter(cx, cont);\n    check_flatten(cx, cont);\n    check_identifier(cx, cont);\n    check_variant_skip_attrs(cx, cont);\n    check_internal_tag_field_name_conflict(cx, cont);\n    check_adjacent_tag_conflict(cx, cont);\n    check_transparent(cx, cont, derive);\n    check_from_and_try_from(cx, cont);\n}\nfn check_from_and_try_from(cx: &Ctxt, cont: &mut Container) {\n    if cont.attrs.type_from().is_some() && cont.attrs.type_try_from().is_some() {\n        cx.error_spanned_by(\n            cont.original,\n            \"#[serde(from = \\\"...\\\")] and #[serde(try_from = \\\"...\\\")] conflict with each other\",\n        );\n    }\n}\n",
        "review_type": "function",
        "repo": "serde-rs/serde",
        "issue_detail": {
            "location": "serde_derive/src/internals/check.rs: line: 1-7, line: 16-22, line: 475-478, ",
            "description": "No unreachable warning when duplicate field names on enum after rename attributes  \nLooking into the rename feature I discovered that rustc does not gives an unreachable warning with serde rename collisions with `enums` whereas it does on `structs` as mentioned in #754 \r\n\r\nWould you still be open to a PR to make clashing renames an error? If so I'm happy to give it a go.\r\n\r\n## Example\r\n```rust\r\nuse serde::{Deserialize};\r\n\r\n#[derive(Deserialize)]\r\nenum Message {\r\n    #[serde(rename = \"Response\")]\r\n    Request { id: String},\r\n    #[serde(rename = \"Response\")]\r\n    Response { id: String},\r\n}\r\n\r\nfn main() {\r\n    let json = \"{\\\"Response\\\": {\\\"id\\\": \\\"...\\\"}}\";\r\n    \r\n    let parsed: Message = match serde_json::from_str(&json) {\r\n        Ok(contact) => contact,\r\n        Err(err) => {\r\n            println!(\"{:?}\", err);\r\n            unimplemented!()\r\n        }\r\n    };\r\n\r\n    match parsed {\r\n        Message::Request { id } => println!(\"request {}\", id),\r\n        Message::Response { id } => println!(\"response {}\", id)\r\n    }\r\n    \r\n}\r\n```\r\n### Output\r\n`request ...`\r\nwith no compiler warnings\r\n\r\nplaygrounds link https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=c6a787d51f1290af999a0e36b9a6d366\r\n\nField/variant aliases are not checked for uniqueness\n[The code](https://play.rust-lang.org/?version=stable&mode=debug&edition=2018&gist=0551945af3b0581fefd8c0c9684e4182)\r\n```rust\r\nuse serde::Deserialize; // 1.0.171;\r\nuse serde_json; // 1.0.102;\r\n\r\n#[derive(Deserialize, Debug)]\r\n#[serde(deny_unknown_fields)]\r\npub struct Thing {\r\n    pub w: u8,\r\n\r\n    #[serde(alias = \"z\", alias = \"x\")]\r\n    pub y: u8,\r\n\r\n    #[serde(alias = \"same\", alias = \"other\", alias = \"same\", alias = \"x\", alias = \"y\")]\r\n    pub same: u8,\r\n}\r\n\r\nfn main() {\r\n    let j = r#\" {\"j\":null} \"#;\r\n    println!(\"{}\", serde_json::from_str::<Thing>(j).unwrap_err());\r\n}\r\n```\r\ngives the following output:\r\n```\r\nunknown field `j`, expected one of `w`, `x`, `z`, `y`, `other`, `same`, `x`, `y` at line 1 column 5\r\n```\n"
        },
        "branch": "alias-check",
        "file_path": "serde_derive/src/internals/check.rs",
        "language": "rust"
    },
    {
        "instance_id": "dtolnay__proc-macro2-236",
        "code_snippet": "fn main() {\n    println!(\"cargo:rerun-if-changed=build.rs\");\n\n    let version = match rustc_version() {\n        Some(version) => version,\n        None => return,\n    };\n\n    if version.minor < 31 {\n        eprintln!(\"Minimum supported rustc version is 1.31\");\n        process::exit(1);\n    }\n\n    let semver_exempt = cfg!(procmacro2_semver_exempt);\n    if semver_exempt {\n        // https://github.com/alexcrichton/proc-macro2/issues/147\n        println!(\"cargo:rustc-cfg=procmacro2_semver_exempt\");\n    }\n\n    if semver_exempt || cfg!(feature = \"span-locations\") {\n        println!(\"cargo:rustc-cfg=span_locations\");\n    }\n\n    if version.minor >= 45 {\n        println!(\"cargo:rustc-cfg=hygiene\");\n    }\n\n    let target = env::var(\"TARGET\").unwrap();\n    if !enable_use_proc_macro(&target) {\n        return;\n    }\n\n    println!(\"cargo:rustc-cfg=use_proc_macro\");\n\n    if version.nightly || !semver_exempt {\n        println!(\"cargo:rustc-cfg=wrap_proc_macro\");\n    }\n\n    if version.nightly && feature_allowed(\"proc_macro_span\") {\n        println!(\"cargo:rustc-cfg=proc_macro_span\");\n    }\n\n    if semver_exempt && version.nightly {\n        println!(\"cargo:rustc-cfg=super_unstable\");\n    }\n}\n    fn take_inner(&mut self) -> Vec<TokenTree> {\n        mem::replace(&mut self.inner, Vec::new())\n    }\n    fn from(tree: TokenTree) -> TokenStream {\n        TokenStream { inner: vec![tree] }\n    }\n",
        "target_function": "fn main() {\n    println!(\"cargo:rerun-if-changed=build.rs\");\n\n    let version = match rustc_version() {\n        Some(version) => version,\n        None => return,\n    };\n\n    if version.minor < 31 {\n        eprintln!(\"Minimum supported rustc version is 1.31\");\n        process::exit(1);\n    }\n\n    let semver_exempt = cfg!(procmacro2_semver_exempt);\n    if semver_exempt {\n        // https://github.com/alexcrichton/proc-macro2/issues/147\n        println!(\"cargo:rustc-cfg=procmacro2_semver_exempt\");\n    }\n\n    if semver_exempt || cfg!(feature = \"span-locations\") {\n        println!(\"cargo:rustc-cfg=span_locations\");\n    }\n\n    if version.minor >= 45 {\n        println!(\"cargo:rustc-cfg=hygiene\");\n    }\n\n    let target = env::var(\"TARGET\").unwrap();\n    if !enable_use_proc_macro(&target) {\n        return;\n    }\n\n    println!(\"cargo:rustc-cfg=use_proc_macro\");\n\n    if version.nightly || !semver_exempt {\n        println!(\"cargo:rustc-cfg=wrap_proc_macro\");\n    }\n\n    if version.nightly && feature_allowed(\"proc_macro_span\") {\n        println!(\"cargo:rustc-cfg=proc_macro_span\");\n    }\n\n    if semver_exempt && version.nightly {\n        println!(\"cargo:rustc-cfg=super_unstable\");\n    }\n}\n    fn take_inner(&mut self) -> Vec<TokenTree> {\n        mem::replace(&mut self.inner, Vec::new())\n    }\n    fn from(tree: TokenTree) -> TokenStream {\n        TokenStream { inner: vec![tree] }\n    }\n",
        "review_type": "function",
        "repo": "dtolnay/proc-macro2",
        "issue_detail": {
            "location": "build.rs: line: 61-67, src/fallback.rs: line: 49-55, line: 172-191, line: 201-209, ",
            "description": "Fallback handling of negative integer literals is different to proc_macro\nThis crate's fallback implementation of `From<TokenTree>` for `TokenStream` treats negative integer literals as one token, however `rustc`'s implementation treats negative integer literals as an alone `-` followed by the positive integer literal.\r\n\r\n### How to Reproduce\r\n\r\n1. Make a simple proc-macro crate, with this code:\r\n```rust\r\nuse std::iter;\r\nuse proc_macro2::{TokenStream, TokenTree, Literal};\r\n\r\n#[proc_macro]\r\npub fn proc_macro_test(input: proc_macro::TokenStream) -> proc_macro::TokenStream {\r\n    //proc_macro2::fallback::force();\r\n\r\n    let int: i32 = -3;\r\n    let mut tokens = TokenStream::new();\r\n    tokens.extend(iter::once(TokenTree::Literal(Literal::i32_suffixed(int))));\r\n    dbg!(&tokens);\r\n\r\n    input\r\n}\r\n```\r\n2. Run that proc macro in another crate. With the commented line commented it will output two separate tokens, but with it uncommented it will output one negative literal token.\n"
        },
        "branch": "negative",
        "file_path": "build.rs,src/fallback.rs",
        "language": "rust"
    },
    {
        "instance_id": "tokio-rs__tokio-3965",
        "code_snippet": "fn poll_future<T: Future>(\n    header: &Header,\n    core: &CoreStage<T>,\n    snapshot: Snapshot,\n    cx: Context<'_>,\n) -> PollFuture<T::Output> {\n    if snapshot.is_cancelled() {\n        PollFuture::Complete(Err(JoinError::cancelled()), snapshot.is_join_interested())\n    } else {\n        let res = panic::catch_unwind(panic::AssertUnwindSafe(|| {\n            struct Guard<'a, T: Future> {\n                core: &'a CoreStage<T>,\n            }\n\n            impl<T: Future> Drop for Guard<'_, T> {\n",
        "target_function": "fn poll_future<T: Future>(\n    header: &Header,\n    core: &CoreStage<T>,\n    snapshot: Snapshot,\n    cx: Context<'_>,\n) -> PollFuture<T::Output> {\n    if snapshot.is_cancelled() {\n        PollFuture::Complete(Err(JoinError::cancelled()), snapshot.is_join_interested())\n    } else {\n        let res = panic::catch_unwind(panic::AssertUnwindSafe(|| {\n            struct Guard<'a, T: Future> {\n                core: &'a CoreStage<T>,\n            }\n\n            impl<T: Future> Drop for Guard<'_, T> {\n",
        "review_type": "function",
        "repo": "tokio-rs/tokio",
        "issue_detail": {
            "location": "tokio/src/runtime/task/harness.rs: line: 420-427, ",
            "description": "JoinHandle::abort has no effect if the handle is immediately dropped\n**Version**\r\nBroken versions: 1.8.1, 1.5.1\r\nWorking versions: 1.8.0, 1.4.0\r\n\r\nLikely culprit: https://github.com/tokio-rs/tokio/pull/3934/files\r\n\r\n**Description**\r\nJoinHandle::abort appears to have no effect if the handle is immedaitely dropped.\r\n\r\nhttps://play.rust-lang.org/?version=stable&mode=debug&edition=2018&gist=1c5d5a22a30f8318fcc731df7d185f14\r\n\r\nThis should print `TraceDrop::drop(\"trace\")` *before* printing `after pause`, but it's actually printed afterwards.\r\n\r\nIf you comment out the line `drop(handle)` then it behaves as expected.\r\n\n"
        },
        "branch": "db-fix-leaked-future",
        "file_path": "tokio/src/runtime/task/harness.rs",
        "language": "rust"
    },
    {
        "instance_id": "asterinas__asterinas-1328",
        "code_snippet": "fn init_thread() {\n    println!(\n        \"[kernel] Spawn init thread, tid = {}\",\n        current_thread!().tid()\n    );\n    // Work queue should be initialized before interrupt is enabled,\n    // in case any irq handler uses work queue as bottom half\n    thread::work_queue::init();\n    net::lazy_init();\n    fs::lazy_init();\n    ipc::init();\n    // driver::pci::virtio::block::block_device_test();\n    let thread = Thread::spawn_kernel_thread(ThreadOptions::new(|| {\n        println!(\"[kernel] Hello world from kernel!\");\n        let current = current_thread!();\n        let tid = current.tid();\n        debug!(\"current tid = {}\", tid);\n    }));\n    thread.join();\n    info!(\n        \"[aster-nix/lib.rs] spawn kernel thread, tid = {}\",\n        thread.tid()\n    );\n\n    print_banner();\n\n    let karg = boot::kernel_cmdline();\n\n    let initproc = Process::spawn_user_process(\n        karg.get_initproc_path().unwrap(),\n        karg.get_initproc_argv().to_vec(),\n        karg.get_initproc_envp().to_vec(),\n    )\n    .expect(\"Run init process failed.\");\n    // Wait till initproc become zombie.\n    while !initproc.is_zombie() {\n        // We don't have preemptive scheduler now.\n        // The long running init thread should yield its own execution to allow other tasks to go on.\n        Thread::yield_now();\n    }\n\n    // TODO: exit via qemu isa debug device should not be the only way.\n    let exit_code = if initproc.exit_code() == 0 {\n        QemuExitCode::Success\n    } else {\n        QemuExitCode::Failed\n    };\n    exit_qemu(exit_code);\n}\nfn clone_child_process(\n    ctx: &Context,\n    parent_context: &UserContext,\n    clone_args: CloneArgs,\n) -> Result<Arc<Process>> {\n    let Context {\n        process,\n        posix_thread,\n        thread: _,\n        task: _,\n    } = ctx;\n\n    let clone_flags = clone_args.clone_flags;\n\n    // clone vm\n    let child_process_vm = {\n        let parent_process_vm = process.vm();\n        clone_vm(parent_process_vm, clone_flags)?\n    };\n\n    // clone user space\n    let child_user_space = {\n        let child_cpu_context = clone_cpu_context(\n            parent_context,\n            clone_args.new_sp,\n            clone_args.stack_size,\n            clone_args.tls,\n            clone_flags,\n        );\n        let child_vm_space = {\n            let child_root_vmar = child_process_vm.root_vmar();\n            child_root_vmar.vm_space().clone()\n        };\n        Arc::new(UserSpace::new(child_vm_space, child_cpu_context))\n    };\n\n    // clone file table\n    let child_file_table = clone_files(process.file_table(), clone_flags);\n\n    // clone fs\n    let child_fs = clone_fs(process.fs(), clone_flags);\n\n    // clone umask\n    let child_umask = {\n        let parent_umask = process.umask().read().get();\n        Arc::new(RwLock::new(FileCreationMask::new(parent_umask)))\n    };\n\n    // clone sig dispositions\n    let child_sig_dispositions = clone_sighand(process.sig_dispositions(), clone_flags);\n\n    // clone system V semaphore\n    clone_sysvsem(clone_flags)?;\n\n    // inherit parent's sig mask\n    let child_sig_mask = posix_thread.sig_mask().load(Ordering::Relaxed).into();\n\n    // inherit parent's nice value\n    let child_nice = process.nice().load(Ordering::Relaxed);\n\n    let child_tid = allocate_tid();\n\n    let child = {\n        let child_elf_path = process.executable_path();\n        let child_thread_builder = {\n            let child_thread_name = ThreadName::new_from_executable_path(&child_elf_path)?;\n\n            let credentials = {\n                let credentials = ctx.posix_thread.credentials();\n                Credentials::new_from(&credentials)\n            };\n\n            PosixThreadBuilder::new(child_tid, child_user_space, credentials)\n                .thread_name(Some(child_thread_name))\n                .sig_mask(child_sig_mask)\n        };\n\n        let mut process_builder =\n            ProcessBuilder::new(child_tid, &child_elf_path, posix_thread.weak_process());\n\n        process_builder\n            .main_thread_builder(child_thread_builder)\n            .process_vm(child_process_vm)\n            .file_table(child_file_table)\n            .fs(child_fs)\n            .umask(child_umask)\n            .sig_dispositions(child_sig_dispositions)\n            .nice(child_nice);\n\n        process_builder.build()?\n    };\n\n    // Deals with clone flags\n    let child_thread = thread_table::get_thread(child_tid).unwrap();\n    let child_posix_thread = child_thread.as_posix_thread().unwrap();\n    clone_parent_settid(child_tid, clone_args.parent_tidptr, clone_flags)?;\n    clone_child_cleartid(child_posix_thread, clone_args.child_tidptr, clone_flags)?;\n    clone_child_settid(child_posix_thread, clone_args.child_tidptr, clone_flags)?;\n\n    // Sets parent process and group for child process.\n    set_parent_and_group(process, &child);\n\n    Ok(child)\n}\npub fn do_exit_group(term_status: TermStatus) {\n    let current = current!();\n    debug!(\"exit group was called\");\n    if current.is_zombie() {\n        return;\n    }\n    current.set_zombie(term_status);\n\n    // Exit all threads\n    let threads = current.threads().lock().clone();\n    for thread in threads {\n        if let Err(e) = do_exit(thread, term_status) {\n            debug!(\"Ignore error when call exit: {:?}\", e);\n        }\n    }\n\n    // Sends parent-death signal\n    // FIXME: according to linux spec, the signal should be sent when a posix thread which\n    // creates child process exits, not when the whole process exits group.\n    for (_, child) in current.children().lock().iter() {\n        let Some(signum) = child.parent_death_signal() else {\n            continue;\n        };\n\n        // FIXME: set pid of the signal\n        let signal = KernelSignal::new(signum);\n        child.enqueue_signal(signal);\n    }\n\n    // Close all files then exit the process\n    let files = current.file_table().lock().close_all();\n    drop(files);\n\n    // Move children to the init process\n    if !is_init_process(&current) {\n        if let Some(init_process) = get_init_process() {\n            let mut init_children = init_process.children().lock();\n            for (_, child_process) in current.children().lock().extract_if(|_, _| true) {\n                let mut parent = child_process.parent.lock();\n                init_children.insert(child_process.pid(), child_process.clone());\n                parent.set_process(&init_process);\n            }\n        }\n    }\n\n    let parent = current.parent().lock().process();\n    if let Some(parent) = parent.upgrade() {\n        // Notify parent\n        let signal = KernelSignal::new(SIGCHLD);\n        parent.enqueue_signal(signal);\n        parent.children_wait_queue().wake_all();\n    }\n}\npub fn kill_all(signal: Option<UserSignal>, ctx: &Context) -> Result<()> {\n    let current = current!();\n    for process in process_table::process_table().iter() {\n        if Arc::ptr_eq(&current, process) || process.is_init_process() {\n            continue;\n        }\n\n        kill_process(process, signal, ctx)?;\n    }\n\n    Ok(())\n}\nfn kill_process(process: &Process, signal: Option<UserSignal>, ctx: &Context) -> Result<()> {\n    let threads = process.threads().lock();\n\n    let signum = signal.map(|signal| signal.num());\n    let sender_ids = current_thread_sender_ids(signum.as_ref(), ctx);\n\n    let mut permitted_thread = None;\n    for thread in threads.iter() {\n        let posix_thread = thread.as_posix_thread().unwrap();\n\n        // First check permission\n        if posix_thread\n            .check_signal_perm(signum.as_ref(), &sender_ids)\n            .is_ok()\n        {\n            let Some(ref signum) = signum else {\n                // If signal is None, only permission check is required\n                return Ok(());\n            };\n\n            if !posix_thread.has_signal_blocked(*signum) {\n                // Send signal to any thread that does not blocks the signal.\n                let signal = signal.unwrap();\n                posix_thread.enqueue_signal(Box::new(signal));\n                return Ok(());\n            } else if permitted_thread.is_none() {\n                permitted_thread = Some(posix_thread);\n            }\n        }\n    }\n\n    let Some(permitted_thread) = permitted_thread else {\n        return_errno_with_message!(Errno::EPERM, \"cannot send signal to the target process\");\n    };\n\n    // If signal is None, only permission check is required\n    let Some(signal) = signal else { return Ok(()) };\n\n    // If all threads block the signal, send signal to the first thread.\n    permitted_thread.enqueue_signal(Box::new(signal));\n\n    Ok(())\n}\n    pub fn build(self) -> Arc<Thread> {\n        let Self {\n            tid,\n            user_space,\n            process,\n            credentials,\n            thread_name,\n            set_child_tid,\n            clear_child_tid,\n            sig_mask,\n            sig_queues,\n        } = self;\n\n        let thread = Arc::new_cyclic(|thread_ref| {\n            let task = task::create_new_user_task(user_space, thread_ref.clone());\n            let status = ThreadStatus::Init;\n\n            let prof_clock = ProfClock::new();\n            let virtual_timer_manager = TimerManager::new(prof_clock.user_clock().clone());\n            let prof_timer_manager = TimerManager::new(prof_clock.clone());\n\n            let posix_thread = PosixThread {\n                process,\n                name: Mutex::new(thread_name),\n                set_child_tid: Mutex::new(set_child_tid),\n                clear_child_tid: Mutex::new(clear_child_tid),\n                credentials,\n                sig_mask,\n                sig_queues,\n                sig_context: Mutex::new(None),\n                sig_stack: Mutex::new(None),\n                signalled_waker: SpinLock::new(None),\n                robust_list: Mutex::new(None),\n                prof_clock,\n                virtual_timer_manager,\n                prof_timer_manager,\n            };\n\n            Thread::new(tid, task, posix_thread, status)\n        });\n        thread_table::add_thread(thread.clone());\n        thread\n    }\npub fn do_exit(thread: Arc<Thread>, term_status: TermStatus) -> Result<()> {\n    if thread.status().is_exited() {\n        return Ok(());\n    }\n    thread.exit();\n\n    let tid = thread.tid();\n\n    let posix_thread = thread.as_posix_thread().unwrap();\n\n    let mut clear_ctid = posix_thread.clear_child_tid().lock();\n    // If clear_ctid !=0 ,do a futex wake and write zero to the clear_ctid addr.\n    if *clear_ctid != 0 {\n        futex_wake(*clear_ctid, 1)?;\n        // FIXME: the correct write length?\n        CurrentUserSpace::get()\n            .write_val(*clear_ctid, &0u32)\n            .unwrap();\n        *clear_ctid = 0;\n    }\n    // exit the robust list: walk the robust list; mark futex words as dead and do futex wake\n    wake_robust_list(posix_thread, tid);\n\n    if tid != posix_thread.process().pid() {\n        // We don't remove main thread.\n        // The main thread is removed when the process is reaped.\n        thread_table::remove_thread(tid);\n    }\n\n    if posix_thread.is_main_thread(tid) || posix_thread.is_last_thread() {\n        // exit current process.\n        do_exit_group(term_status);\n    }\n\n    futex_wake(Arc::as_ptr(&posix_thread.process()) as Vaddr, 1)?;\n    Ok(())\n}\n    pub fn credentials_mut(&self) -> Credentials<WriteOp> {\n        debug_assert!(core::ptr::eq(\n            current_thread!().as_posix_thread().unwrap(),\n            self\n        ));\n        self.credentials.dup().restrict()\n    }\n    fn as_posix_thread(&self) -> Option<&PosixThread> {\n        self.data().downcast_ref::<PosixThread>()\n    }\n    fn new_posix_thread_from_executable(\n        tid: Tid,\n        credentials: Credentials,\n        process_vm: &ProcessVm,\n        fs_resolver: &FsResolver,\n        executable_path: &str,\n        process: Weak<Process>,\n        argv: Vec<CString>,\n        envp: Vec<CString>,\n    ) -> Result<Arc<Self>> {\n        let elf_file = {\n            let fs_path = FsPath::new(AT_FDCWD, executable_path)?;\n            fs_resolver.lookup(&fs_path)?\n        };\n        let (_, elf_load_info) =\n            load_program_to_vm(process_vm, elf_file, argv, envp, fs_resolver, 1)?;\n\n        let vm_space = process_vm.root_vmar().vm_space().clone();\n        let mut cpu_ctx = UserContext::default();\n        cpu_ctx.set_instruction_pointer(elf_load_info.entry_point() as _);\n        cpu_ctx.set_stack_pointer(elf_load_info.user_stack_top() as _);\n        let user_space = Arc::new(UserSpace::new(vm_space, cpu_ctx));\n        let thread_name = Some(ThreadName::new_from_executable_path(executable_path)?);\n        let thread_builder = PosixThreadBuilder::new(tid, user_space, credentials)\n            .thread_name(thread_name)\n            .process(process);\n        Ok(thread_builder.build())\n    }\n    pub fn build(self) -> Result<Arc<Process>> {\n        self.check_build()?;\n        let Self {\n            pid,\n            executable_path,\n            parent,\n            main_thread_builder,\n            argv,\n            envp,\n            process_vm,\n            file_table,\n            fs,\n            umask,\n            resource_limits,\n            sig_dispositions,\n            credentials,\n            nice,\n        } = self;\n\n        let process_vm = process_vm.or_else(|| Some(ProcessVm::alloc())).unwrap();\n\n        let file_table = file_table\n            .or_else(|| Some(Arc::new(SpinLock::new(FileTable::new_with_stdio()))))\n            .unwrap();\n\n        let fs = fs\n            .or_else(|| Some(Arc::new(RwMutex::new(FsResolver::new()))))\n            .unwrap();\n\n        let umask = umask\n            .or_else(|| Some(Arc::new(RwLock::new(FileCreationMask::default()))))\n            .unwrap();\n\n        let resource_limits = resource_limits\n            .or_else(|| Some(ResourceLimits::default()))\n            .unwrap();\n\n        let sig_dispositions = sig_dispositions\n            .or_else(|| Some(Arc::new(Mutex::new(SigDispositions::new()))))\n            .unwrap();\n\n        let nice = nice.or_else(|| Some(Nice::default())).unwrap();\n\n        let process = {\n            let threads = Vec::new();\n            Process::new(\n                pid,\n                parent,\n                threads,\n                executable_path.to_string(),\n                process_vm,\n                fs,\n                file_table,\n                umask,\n                resource_limits,\n                nice,\n                sig_dispositions,\n            )\n        };\n\n        let thread = if let Some(thread_builder) = main_thread_builder {\n            let builder = thread_builder.process(Arc::downgrade(&process));\n            builder.build()\n        } else {\n            Thread::new_posix_thread_from_executable(\n                pid,\n                credentials.unwrap(),\n                process.vm(),\n                &process.fs().read(),\n                executable_path,\n                Arc::downgrade(&process),\n                argv.unwrap(),\n                envp.unwrap(),\n            )?\n        };\n\n        process.threads().lock().push(thread);\n\n        process.set_runnable();\n\n        Ok(process)\n    }\n    pub fn enqueue_signal(&self, signal: impl Signal + Clone + 'static) {\n        if self.is_zombie() {\n            return;\n        }\n\n        // TODO: check that the signal is not user signal\n\n        // Enqueue signal to the first thread that does not block the signal\n        let threads = self.threads.lock();\n        for thread in threads.iter() {\n            let posix_thread = thread.as_posix_thread().unwrap();\n            if !posix_thread.has_signal_blocked(signal.num()) {\n                posix_thread.enqueue_signal(Box::new(signal));\n                return;\n            }\n        }\n\n        // If all threads block the signal, enqueue signal to the first thread\n        let thread = threads.iter().next().unwrap();\n        let posix_thread = thread.as_posix_thread().unwrap();\n        posix_thread.enqueue_signal(Box::new(signal));\n    }\n    fn pause_until_or_timeout_opt<F, R>(&self, mut cond: F, timeout: Option<&Duration>) -> Result<R>\n    where\n        F: FnMut() -> Option<R>,\n    {\n        if let Some(res) = cond() {\n            return Ok(res);\n        }\n\n        let current_thread = self\n            .task()\n            .data()\n            .downcast_ref::<Weak<Thread>>()\n            .and_then(|thread| thread.upgrade());\n\n        let Some(posix_thread) = current_thread\n            .as_ref()\n            .and_then(|thread| thread.as_posix_thread())\n        else {\n            if let Some(timeout) = timeout {\n                return self.wait_until_or_timeout(cond, timeout);\n            } else {\n                return self.wait_until_or_cancelled(cond, || Ok(()));\n            }\n        };\n\n        let cancel_cond = || {\n            if posix_thread.has_pending() {\n                return Err(Error::with_message(\n                    Errno::EINTR,\n                    \"the current thread is interrupted by a signal\",\n                ));\n            }\n            Ok(())\n        };\n\n        posix_thread.set_signalled_waker(self.waker());\n        let res = if let Some(timeout) = timeout {\n            self.wait_until_or_timeout_cancelled(cond, cancel_cond, timeout)\n        } else {\n            self.wait_until_or_cancelled(cond, cancel_cond)\n        };\n        posix_thread.clear_signalled_waker();\n        res\n    }\nfn reap_zombie_child(process: &Process, pid: Pid) -> ExitCode {\n    let child_process = process.children().lock().remove(&pid).unwrap();\n    assert!(child_process.is_zombie());\n    for thread in &*child_process.threads().lock() {\n        thread_table::remove_thread(thread.tid());\n    }\n\n    // Lock order: session table -> group table -> process table -> group of process\n    // -> group inner -> session inner\n    let mut session_table_mut = process_table::session_table_mut();\n    let mut group_table_mut = process_table::group_table_mut();\n    let mut process_table_mut = process_table::process_table_mut();\n\n    let mut child_group_mut = child_process.process_group.lock();\n\n    let process_group = child_group_mut.upgrade().unwrap();\n    let mut group_inner = process_group.inner.lock();\n    let session = group_inner.session.upgrade().unwrap();\n    let mut session_inner = session.inner.lock();\n\n    group_inner.remove_process(&child_process.pid());\n    session_inner.remove_process(&child_process);\n    *child_group_mut = Weak::new();\n\n    if group_inner.is_empty() {\n        group_table_mut.remove(&process_group.pgid());\n        session_inner.remove_process_group(&process_group.pgid());\n\n        if session_inner.is_empty() {\n            session_table_mut.remove(&session.sid());\n        }\n    }\n\n    process_table_mut.remove(&child_process.pid());\n    child_process.exit_code()\n}\npub fn sys_exit(exit_code: i32, _ctx: &Context) -> Result<SyscallReturn> {\n    debug!(\"exid code = {}\", exit_code);\n\n    let current_thread = current_thread!();\n    let term_status = TermStatus::Exited(exit_code as _);\n    do_exit(current_thread, term_status)?;\n\n    Ok(SyscallReturn::Return(0))\n}\npub fn sys_futex(\n    futex_addr: Vaddr,\n    futex_op: i32,\n    futex_val: u32,\n    utime_addr: u64,\n    futex_new_addr: u64,\n    bitset: u64,\n    ctx: &Context,\n) -> Result<SyscallReturn> {\n    // FIXME: we current ignore futex flags\n    let (futex_op, futex_flags) = futex_op_and_flags_from_u32(futex_op as _)?;\n    debug!(\n        \"futex_op = {:?}, futex_flags = {:?}, futex_addr = 0x{:x}\",\n        futex_op, futex_flags, futex_addr\n    );\n\n    let get_futex_val = |val: i32| -> Result<usize> {\n        if val < 0 {\n            return_errno_with_message!(Errno::EINVAL, \"the futex val must not be negative\");\n        }\n        Ok(val as usize)\n    };\n\n    let get_futex_timeout = |timeout_addr| -> Result<Option<FutexTimeout>> {\n        if timeout_addr == 0 {\n            return Ok(None);\n        }\n        // TODO: parse a timeout\n        todo!()\n    };\n\n    let res = match futex_op {\n        FutexOp::FUTEX_WAIT => {\n            let timeout = get_futex_timeout(utime_addr)?;\n            futex_wait(futex_addr as _, futex_val as _, &timeout).map(|_| 0)\n        }\n        FutexOp::FUTEX_WAIT_BITSET => {\n            let timeout = get_futex_timeout(utime_addr)?;\n            futex_wait_bitset(futex_addr as _, futex_val as _, &timeout, bitset as _).map(|_| 0)\n        }\n        FutexOp::FUTEX_WAKE => {\n            let max_count = get_futex_val(futex_val as i32)?;\n            futex_wake(futex_addr as _, max_count).map(|count| count as isize)\n        }\n        FutexOp::FUTEX_WAKE_BITSET => {\n            let max_count = get_futex_val(futex_val as i32)?;\n            futex_wake_bitset(futex_addr as _, max_count, bitset as _).map(|count| count as isize)\n        }\n        FutexOp::FUTEX_REQUEUE => {\n            let max_nwakes = get_futex_val(futex_val as i32)?;\n            let max_nrequeues = get_futex_val(utime_addr as i32)?;\n            futex_requeue(\n                futex_addr as _,\n                max_nwakes,\n                max_nrequeues,\n                futex_new_addr as _,\n            )\n            .map(|nwakes| nwakes as _)\n        }\n        _ => panic!(\"Unsupported futex operations\"),\n    }?;\n\n    debug!(\"futex returns, tid= {} \", ctx.thread.tid());\n    Ok(SyscallReturn::Return(res as _))\n}\npub fn sys_gettid(ctx: &Context) -> Result<SyscallReturn> {\n    let tid = ctx.thread.tid();\n    Ok(SyscallReturn::Return(tid as _))\n}\npub fn sys_set_tid_address(tidptr: Vaddr, ctx: &Context) -> Result<SyscallReturn> {\n    debug!(\"tidptr = 0x{:x}\", tidptr);\n    let mut clear_child_tid = ctx.posix_thread.clear_child_tid().lock();\n    if *clear_child_tid != 0 {\n        // According to manuals at https://man7.org/linux/man-pages/man2/set_tid_address.2.html\n        // We need to write 0 to clear_child_tid and do futex wake\n        todo!()\n    } else {\n        *clear_child_tid = tidptr;\n    }\n    let tid = ctx.thread.tid();\n    Ok(SyscallReturn::Return(tid as _))\n}\n    fn join(&self) {\n        loop {\n            if self.status().is_exited() {\n                return;\n            } else {\n                Thread::yield_now();\n            }\n        }\n    }\n    pub fn data(&self) -> &Box<dyn Send + Sync + Any> {\n        &self.data\n    }\npub fn allocate_tid() -> Tid {\n    TID_ALLOCATOR.fetch_add(1, Ordering::SeqCst)\n}\n    fn user_task_entry() {\n        let current_thread = current_thread!();\n        let current_posix_thread = current_thread.as_posix_thread().unwrap();\n        let current_process = current_posix_thread.process();\n        let current_task = current_thread.task();\n\n        let user_space = current_task\n            .user_space()\n            .expect(\"user task should have user space\");\n        let mut user_mode = UserMode::new(user_space);\n        debug!(\n            \"[Task entry] rip = 0x{:x}\",\n            user_mode.context().instruction_pointer()\n        );\n        debug!(\n            \"[Task entry] rsp = 0x{:x}\",\n            user_mode.context().stack_pointer()\n        );\n        debug!(\n            \"[Task entry] rax = 0x{:x}\",\n            user_mode.context().syscall_ret()\n        );\n\n        let child_tid_ptr = *current_posix_thread.set_child_tid().lock();\n\n        // The `clone` syscall may require child process to write the thread pid to the specified address.\n        // Make sure the store operation completes before the clone call returns control to user space\n        // in the child process.\n        if is_userspace_vaddr(child_tid_ptr) {\n            CurrentUserSpace::get()\n                .write_val(child_tid_ptr, &current_thread.tid())\n                .unwrap();\n        }\n\n        let has_kernel_event_fn = || current_posix_thread.has_pending();\n\n        let ctx = Context {\n            process: current_process.as_ref(),\n            posix_thread: current_posix_thread,\n            thread: current_thread.as_ref(),\n            task: current_task.as_ref(),\n        };\n\n        loop {\n            let return_reason = user_mode.execute(has_kernel_event_fn);\n            let user_ctx = user_mode.context_mut();\n            // handle user event:\n            match return_reason {\n                ReturnReason::UserException => handle_exception(&ctx, user_ctx),\n                ReturnReason::UserSyscall => handle_syscall(&ctx, user_ctx),\n                ReturnReason::KernelEvent => {}\n            };\n\n            if current_thread.status().is_exited() {\n                break;\n            }\n            handle_pending_signal(user_ctx, &current_thread).unwrap();\n            // If current is suspended, wait for a signal to wake up self\n            while current_thread.status().is_stopped() {\n                Thread::yield_now();\n                debug!(\"{} is suspended.\", current_thread.tid());\n                handle_pending_signal(user_ctx, &current_thread).unwrap();\n            }\n            if current_thread.status().is_exited() {\n                debug!(\"exit due to signal\");\n                break;\n            }\n        }\n        debug!(\"exit user loop\");\n    }\npub fn add_thread(thread: Arc<Thread>) {\n    let tid = thread.tid();\n    THREAD_TABLE.lock().insert(tid, thread);\n}\npub fn remove_thread(tid: Tid) {\n    THREAD_TABLE.lock().remove(&tid);\n}\npub fn get_thread(tid: Tid) -> Option<Arc<Thread>> {\n    THREAD_TABLE.lock().get(&tid).cloned()\n}\n    fn run_worker_loop(self: &Arc<Self>) {\n        loop {\n            let worker_pool = self.worker_pool.upgrade();\n            let Some(worker_pool) = worker_pool else {\n                break;\n            };\n            if let Some(work_item) = worker_pool.fetch_pending_work_item(self.bound_cpu) {\n                work_item.set_processing();\n                work_item.call_work_func();\n                worker_pool.set_heartbeat(self.bound_cpu, true);\n            } else {\n                if self.is_destroying() {\n                    break;\n                }\n                self.inner.disable_irq().lock().worker_status = WorkerStatus::Idle;\n                worker_pool.idle_current_worker(self.bound_cpu, self.clone());\n                if !self.is_destroying() {\n                    self.inner.disable_irq().lock().worker_status = WorkerStatus::Running;\n                }\n            }\n        }\n        self.exit();\n    }\n    pub(super) fn bound_thread(&self) -> &Arc<Thread> {\n        &self.bound_thread\n    }\n    pub(super) fn is_idle(&self) -> bool {\n        self.inner.disable_irq().lock().worker_status == WorkerStatus::Idle\n    }\n    pub fn new(worker_pool: Weak<WorkerPool>, priority: &WorkPriority) -> Arc<Self> {\n        Arc::new_cyclic(|monitor_ref| {\n            let weal_monitor = monitor_ref.clone();\n            let task_fn = Box::new(move || {\n                let current_monitor: Arc<Monitor> = weal_monitor.upgrade().unwrap();\n                current_monitor.run_monitor_loop();\n            });\n            let cpu_affinity = CpuSet::new_full();\n            let priority = match priority {\n                WorkPriority::High => Priority::high(),\n                WorkPriority::Normal => Priority::normal(),\n            };\n            let bound_thread = Thread::new_kernel_thread(\n                ThreadOptions::new(task_fn)\n                    .cpu_affinity(cpu_affinity)\n                    .priority(priority),\n            );\n            Self {\n                worker_pool,\n                bound_thread,\n            }\n        })\n    }\n    pub fn run(&self) {\n        self.bound_thread.run();\n    }\n    fn run_monitor_loop(self: &Arc<Self>) {\n        let sleep_queue = WaitQueue::new();\n        let sleep_duration = Duration::from_millis(100);\n        loop {\n            let worker_pool = self.worker_pool.upgrade();\n            let Some(worker_pool) = worker_pool else {\n                break;\n            };\n            worker_pool.schedule();\n            for local_pool in worker_pool.local_pools.iter() {\n                local_pool.set_heartbeat(false);\n            }\n            let _ = sleep_queue.wait_until_or_timeout(|| -> Option<()> { None }, &sleep_duration);\n        }\n    }\n    pub fn build(self) -> Result<Arc<Task>> {\n        /// all task will entering this function\n        /// this function is mean to executing the task_fn in Task\n        extern \"C\" fn kernel_task_entry() {\n            let current_task = current_task()\n                .expect(\"no current task, it should have current task in kernel task entry\");\n            current_task.func.call(());\n            current_task.exit();\n        }\n\n        let mut new_task = Task {\n            func: self.func.unwrap(),\n            data: self.data.unwrap(),\n            user_space: self.user_space,\n            ctx: UnsafeCell::new(TaskContext::default()),\n            kstack: KernelStack::new_with_guard_page()?,\n            schedule_info: TaskScheduleInfo {\n                cpu: AtomicCpuId::default(),\n                priority: self.priority,\n                cpu_affinity: self.cpu_affinity,\n            },\n        };\n\n        let ctx = new_task.ctx.get_mut();\n        ctx.set_instruction_pointer(kernel_task_entry as usize);\n        // We should reserve space for the return address in the stack, otherwise\n        // we will write across the page boundary due to the implementation of\n        // the context switch.\n        //\n        // According to the System V AMD64 ABI, the stack pointer should be aligned\n        // to at least 16 bytes. And a larger alignment is needed if larger arguments\n        // are passed to the function. The `kernel_task_entry` function does not\n        // have any arguments, so we only need to align the stack pointer to 16 bytes.\n        ctx.set_stack_pointer(crate::mm::paddr_to_vaddr(new_task.kstack.end_paddr() - 16));\n\n        Ok(Arc::new(new_task))\n    }\n    pub fn spawn(self) -> Result<Arc<Task>> {\n        let task = self.build()?;\n        task.run();\n        Ok(task)\n    }\n",
        "target_function": "fn init_thread() {\n    println!(\n        \"[kernel] Spawn init thread, tid = {}\",\n        current_thread!().tid()\n    );\n    // Work queue should be initialized before interrupt is enabled,\n    // in case any irq handler uses work queue as bottom half\n    thread::work_queue::init();\n    net::lazy_init();\n    fs::lazy_init();\n    ipc::init();\n    // driver::pci::virtio::block::block_device_test();\n    let thread = Thread::spawn_kernel_thread(ThreadOptions::new(|| {\n        println!(\"[kernel] Hello world from kernel!\");\n        let current = current_thread!();\n        let tid = current.tid();\n        debug!(\"current tid = {}\", tid);\n    }));\n    thread.join();\n    info!(\n        \"[aster-nix/lib.rs] spawn kernel thread, tid = {}\",\n        thread.tid()\n    );\n\n    print_banner();\n\n    let karg = boot::kernel_cmdline();\n\n    let initproc = Process::spawn_user_process(\n        karg.get_initproc_path().unwrap(),\n        karg.get_initproc_argv().to_vec(),\n        karg.get_initproc_envp().to_vec(),\n    )\n    .expect(\"Run init process failed.\");\n    // Wait till initproc become zombie.\n    while !initproc.is_zombie() {\n        // We don't have preemptive scheduler now.\n        // The long running init thread should yield its own execution to allow other tasks to go on.\n        Thread::yield_now();\n    }\n\n    // TODO: exit via qemu isa debug device should not be the only way.\n    let exit_code = if initproc.exit_code() == 0 {\n        QemuExitCode::Success\n    } else {\n        QemuExitCode::Failed\n    };\n    exit_qemu(exit_code);\n}\nfn clone_child_process(\n    ctx: &Context,\n    parent_context: &UserContext,\n    clone_args: CloneArgs,\n) -> Result<Arc<Process>> {\n    let Context {\n        process,\n        posix_thread,\n        thread: _,\n        task: _,\n    } = ctx;\n\n    let clone_flags = clone_args.clone_flags;\n\n    // clone vm\n    let child_process_vm = {\n        let parent_process_vm = process.vm();\n        clone_vm(parent_process_vm, clone_flags)?\n    };\n\n    // clone user space\n    let child_user_space = {\n        let child_cpu_context = clone_cpu_context(\n            parent_context,\n            clone_args.new_sp,\n            clone_args.stack_size,\n            clone_args.tls,\n            clone_flags,\n        );\n        let child_vm_space = {\n            let child_root_vmar = child_process_vm.root_vmar();\n            child_root_vmar.vm_space().clone()\n        };\n        Arc::new(UserSpace::new(child_vm_space, child_cpu_context))\n    };\n\n    // clone file table\n    let child_file_table = clone_files(process.file_table(), clone_flags);\n\n    // clone fs\n    let child_fs = clone_fs(process.fs(), clone_flags);\n\n    // clone umask\n    let child_umask = {\n        let parent_umask = process.umask().read().get();\n        Arc::new(RwLock::new(FileCreationMask::new(parent_umask)))\n    };\n\n    // clone sig dispositions\n    let child_sig_dispositions = clone_sighand(process.sig_dispositions(), clone_flags);\n\n    // clone system V semaphore\n    clone_sysvsem(clone_flags)?;\n\n    // inherit parent's sig mask\n    let child_sig_mask = posix_thread.sig_mask().load(Ordering::Relaxed).into();\n\n    // inherit parent's nice value\n    let child_nice = process.nice().load(Ordering::Relaxed);\n\n    let child_tid = allocate_tid();\n\n    let child = {\n        let child_elf_path = process.executable_path();\n        let child_thread_builder = {\n            let child_thread_name = ThreadName::new_from_executable_path(&child_elf_path)?;\n\n            let credentials = {\n                let credentials = ctx.posix_thread.credentials();\n                Credentials::new_from(&credentials)\n            };\n\n            PosixThreadBuilder::new(child_tid, child_user_space, credentials)\n                .thread_name(Some(child_thread_name))\n                .sig_mask(child_sig_mask)\n        };\n\n        let mut process_builder =\n            ProcessBuilder::new(child_tid, &child_elf_path, posix_thread.weak_process());\n\n        process_builder\n            .main_thread_builder(child_thread_builder)\n            .process_vm(child_process_vm)\n            .file_table(child_file_table)\n            .fs(child_fs)\n            .umask(child_umask)\n            .sig_dispositions(child_sig_dispositions)\n            .nice(child_nice);\n\n        process_builder.build()?\n    };\n\n    // Deals with clone flags\n    let child_thread = thread_table::get_thread(child_tid).unwrap();\n    let child_posix_thread = child_thread.as_posix_thread().unwrap();\n    clone_parent_settid(child_tid, clone_args.parent_tidptr, clone_flags)?;\n    clone_child_cleartid(child_posix_thread, clone_args.child_tidptr, clone_flags)?;\n    clone_child_settid(child_posix_thread, clone_args.child_tidptr, clone_flags)?;\n\n    // Sets parent process and group for child process.\n    set_parent_and_group(process, &child);\n\n    Ok(child)\n}\npub fn do_exit_group(term_status: TermStatus) {\n    let current = current!();\n    debug!(\"exit group was called\");\n    if current.is_zombie() {\n        return;\n    }\n    current.set_zombie(term_status);\n\n    // Exit all threads\n    let threads = current.threads().lock().clone();\n    for thread in threads {\n        if let Err(e) = do_exit(thread, term_status) {\n            debug!(\"Ignore error when call exit: {:?}\", e);\n        }\n    }\n\n    // Sends parent-death signal\n    // FIXME: according to linux spec, the signal should be sent when a posix thread which\n    // creates child process exits, not when the whole process exits group.\n    for (_, child) in current.children().lock().iter() {\n        let Some(signum) = child.parent_death_signal() else {\n            continue;\n        };\n\n        // FIXME: set pid of the signal\n        let signal = KernelSignal::new(signum);\n        child.enqueue_signal(signal);\n    }\n\n    // Close all files then exit the process\n    let files = current.file_table().lock().close_all();\n    drop(files);\n\n    // Move children to the init process\n    if !is_init_process(&current) {\n        if let Some(init_process) = get_init_process() {\n            let mut init_children = init_process.children().lock();\n            for (_, child_process) in current.children().lock().extract_if(|_, _| true) {\n                let mut parent = child_process.parent.lock();\n                init_children.insert(child_process.pid(), child_process.clone());\n                parent.set_process(&init_process);\n            }\n        }\n    }\n\n    let parent = current.parent().lock().process();\n    if let Some(parent) = parent.upgrade() {\n        // Notify parent\n        let signal = KernelSignal::new(SIGCHLD);\n        parent.enqueue_signal(signal);\n        parent.children_wait_queue().wake_all();\n    }\n}\npub fn kill_all(signal: Option<UserSignal>, ctx: &Context) -> Result<()> {\n    let current = current!();\n    for process in process_table::process_table().iter() {\n        if Arc::ptr_eq(&current, process) || process.is_init_process() {\n            continue;\n        }\n\n        kill_process(process, signal, ctx)?;\n    }\n\n    Ok(())\n}\nfn kill_process(process: &Process, signal: Option<UserSignal>, ctx: &Context) -> Result<()> {\n    let threads = process.threads().lock();\n\n    let signum = signal.map(|signal| signal.num());\n    let sender_ids = current_thread_sender_ids(signum.as_ref(), ctx);\n\n    let mut permitted_thread = None;\n    for thread in threads.iter() {\n        let posix_thread = thread.as_posix_thread().unwrap();\n\n        // First check permission\n        if posix_thread\n            .check_signal_perm(signum.as_ref(), &sender_ids)\n            .is_ok()\n        {\n            let Some(ref signum) = signum else {\n                // If signal is None, only permission check is required\n                return Ok(());\n            };\n\n            if !posix_thread.has_signal_blocked(*signum) {\n                // Send signal to any thread that does not blocks the signal.\n                let signal = signal.unwrap();\n                posix_thread.enqueue_signal(Box::new(signal));\n                return Ok(());\n            } else if permitted_thread.is_none() {\n                permitted_thread = Some(posix_thread);\n            }\n        }\n    }\n\n    let Some(permitted_thread) = permitted_thread else {\n        return_errno_with_message!(Errno::EPERM, \"cannot send signal to the target process\");\n    };\n\n    // If signal is None, only permission check is required\n    let Some(signal) = signal else { return Ok(()) };\n\n    // If all threads block the signal, send signal to the first thread.\n    permitted_thread.enqueue_signal(Box::new(signal));\n\n    Ok(())\n}\n    pub fn build(self) -> Arc<Thread> {\n        let Self {\n            tid,\n            user_space,\n            process,\n            credentials,\n            thread_name,\n            set_child_tid,\n            clear_child_tid,\n            sig_mask,\n            sig_queues,\n        } = self;\n\n        let thread = Arc::new_cyclic(|thread_ref| {\n            let task = task::create_new_user_task(user_space, thread_ref.clone());\n            let status = ThreadStatus::Init;\n\n            let prof_clock = ProfClock::new();\n            let virtual_timer_manager = TimerManager::new(prof_clock.user_clock().clone());\n            let prof_timer_manager = TimerManager::new(prof_clock.clone());\n\n            let posix_thread = PosixThread {\n                process,\n                name: Mutex::new(thread_name),\n                set_child_tid: Mutex::new(set_child_tid),\n                clear_child_tid: Mutex::new(clear_child_tid),\n                credentials,\n                sig_mask,\n                sig_queues,\n                sig_context: Mutex::new(None),\n                sig_stack: Mutex::new(None),\n                signalled_waker: SpinLock::new(None),\n                robust_list: Mutex::new(None),\n                prof_clock,\n                virtual_timer_manager,\n                prof_timer_manager,\n            };\n\n            Thread::new(tid, task, posix_thread, status)\n        });\n        thread_table::add_thread(thread.clone());\n        thread\n    }\npub fn do_exit(thread: Arc<Thread>, term_status: TermStatus) -> Result<()> {\n    if thread.status().is_exited() {\n        return Ok(());\n    }\n    thread.exit();\n\n    let tid = thread.tid();\n\n    let posix_thread = thread.as_posix_thread().unwrap();\n\n    let mut clear_ctid = posix_thread.clear_child_tid().lock();\n    // If clear_ctid !=0 ,do a futex wake and write zero to the clear_ctid addr.\n    if *clear_ctid != 0 {\n        futex_wake(*clear_ctid, 1)?;\n        // FIXME: the correct write length?\n        CurrentUserSpace::get()\n            .write_val(*clear_ctid, &0u32)\n            .unwrap();\n        *clear_ctid = 0;\n    }\n    // exit the robust list: walk the robust list; mark futex words as dead and do futex wake\n    wake_robust_list(posix_thread, tid);\n\n    if tid != posix_thread.process().pid() {\n        // We don't remove main thread.\n        // The main thread is removed when the process is reaped.\n        thread_table::remove_thread(tid);\n    }\n\n    if posix_thread.is_main_thread(tid) || posix_thread.is_last_thread() {\n        // exit current process.\n        do_exit_group(term_status);\n    }\n\n    futex_wake(Arc::as_ptr(&posix_thread.process()) as Vaddr, 1)?;\n    Ok(())\n}\n    pub fn credentials_mut(&self) -> Credentials<WriteOp> {\n        debug_assert!(core::ptr::eq(\n            current_thread!().as_posix_thread().unwrap(),\n            self\n        ));\n        self.credentials.dup().restrict()\n    }\n    fn as_posix_thread(&self) -> Option<&PosixThread> {\n        self.data().downcast_ref::<PosixThread>()\n    }\n    fn new_posix_thread_from_executable(\n        tid: Tid,\n        credentials: Credentials,\n        process_vm: &ProcessVm,\n        fs_resolver: &FsResolver,\n        executable_path: &str,\n        process: Weak<Process>,\n        argv: Vec<CString>,\n        envp: Vec<CString>,\n    ) -> Result<Arc<Self>> {\n        let elf_file = {\n            let fs_path = FsPath::new(AT_FDCWD, executable_path)?;\n            fs_resolver.lookup(&fs_path)?\n        };\n        let (_, elf_load_info) =\n            load_program_to_vm(process_vm, elf_file, argv, envp, fs_resolver, 1)?;\n\n        let vm_space = process_vm.root_vmar().vm_space().clone();\n        let mut cpu_ctx = UserContext::default();\n        cpu_ctx.set_instruction_pointer(elf_load_info.entry_point() as _);\n        cpu_ctx.set_stack_pointer(elf_load_info.user_stack_top() as _);\n        let user_space = Arc::new(UserSpace::new(vm_space, cpu_ctx));\n        let thread_name = Some(ThreadName::new_from_executable_path(executable_path)?);\n        let thread_builder = PosixThreadBuilder::new(tid, user_space, credentials)\n            .thread_name(thread_name)\n            .process(process);\n        Ok(thread_builder.build())\n    }\n    pub fn build(self) -> Result<Arc<Process>> {\n        self.check_build()?;\n        let Self {\n            pid,\n            executable_path,\n            parent,\n            main_thread_builder,\n            argv,\n            envp,\n            process_vm,\n            file_table,\n            fs,\n            umask,\n            resource_limits,\n            sig_dispositions,\n            credentials,\n            nice,\n        } = self;\n\n        let process_vm = process_vm.or_else(|| Some(ProcessVm::alloc())).unwrap();\n\n        let file_table = file_table\n            .or_else(|| Some(Arc::new(SpinLock::new(FileTable::new_with_stdio()))))\n            .unwrap();\n\n        let fs = fs\n            .or_else(|| Some(Arc::new(RwMutex::new(FsResolver::new()))))\n            .unwrap();\n\n        let umask = umask\n            .or_else(|| Some(Arc::new(RwLock::new(FileCreationMask::default()))))\n            .unwrap();\n\n        let resource_limits = resource_limits\n            .or_else(|| Some(ResourceLimits::default()))\n            .unwrap();\n\n        let sig_dispositions = sig_dispositions\n            .or_else(|| Some(Arc::new(Mutex::new(SigDispositions::new()))))\n            .unwrap();\n\n        let nice = nice.or_else(|| Some(Nice::default())).unwrap();\n\n        let process = {\n            let threads = Vec::new();\n            Process::new(\n                pid,\n                parent,\n                threads,\n                executable_path.to_string(),\n                process_vm,\n                fs,\n                file_table,\n                umask,\n                resource_limits,\n                nice,\n                sig_dispositions,\n            )\n        };\n\n        let thread = if let Some(thread_builder) = main_thread_builder {\n            let builder = thread_builder.process(Arc::downgrade(&process));\n            builder.build()\n        } else {\n            Thread::new_posix_thread_from_executable(\n                pid,\n                credentials.unwrap(),\n                process.vm(),\n                &process.fs().read(),\n                executable_path,\n                Arc::downgrade(&process),\n                argv.unwrap(),\n                envp.unwrap(),\n            )?\n        };\n\n        process.threads().lock().push(thread);\n\n        process.set_runnable();\n\n        Ok(process)\n    }\n    pub fn enqueue_signal(&self, signal: impl Signal + Clone + 'static) {\n        if self.is_zombie() {\n            return;\n        }\n\n        // TODO: check that the signal is not user signal\n\n        // Enqueue signal to the first thread that does not block the signal\n        let threads = self.threads.lock();\n        for thread in threads.iter() {\n            let posix_thread = thread.as_posix_thread().unwrap();\n            if !posix_thread.has_signal_blocked(signal.num()) {\n                posix_thread.enqueue_signal(Box::new(signal));\n                return;\n            }\n        }\n\n        // If all threads block the signal, enqueue signal to the first thread\n        let thread = threads.iter().next().unwrap();\n        let posix_thread = thread.as_posix_thread().unwrap();\n        posix_thread.enqueue_signal(Box::new(signal));\n    }\n    fn pause_until_or_timeout_opt<F, R>(&self, mut cond: F, timeout: Option<&Duration>) -> Result<R>\n    where\n        F: FnMut() -> Option<R>,\n    {\n        if let Some(res) = cond() {\n            return Ok(res);\n        }\n\n        let current_thread = self\n            .task()\n            .data()\n            .downcast_ref::<Weak<Thread>>()\n            .and_then(|thread| thread.upgrade());\n\n        let Some(posix_thread) = current_thread\n            .as_ref()\n            .and_then(|thread| thread.as_posix_thread())\n        else {\n            if let Some(timeout) = timeout {\n                return self.wait_until_or_timeout(cond, timeout);\n            } else {\n                return self.wait_until_or_cancelled(cond, || Ok(()));\n            }\n        };\n\n        let cancel_cond = || {\n            if posix_thread.has_pending() {\n                return Err(Error::with_message(\n                    Errno::EINTR,\n                    \"the current thread is interrupted by a signal\",\n                ));\n            }\n            Ok(())\n        };\n\n        posix_thread.set_signalled_waker(self.waker());\n        let res = if let Some(timeout) = timeout {\n            self.wait_until_or_timeout_cancelled(cond, cancel_cond, timeout)\n        } else {\n            self.wait_until_or_cancelled(cond, cancel_cond)\n        };\n        posix_thread.clear_signalled_waker();\n        res\n    }\nfn reap_zombie_child(process: &Process, pid: Pid) -> ExitCode {\n    let child_process = process.children().lock().remove(&pid).unwrap();\n    assert!(child_process.is_zombie());\n    for thread in &*child_process.threads().lock() {\n        thread_table::remove_thread(thread.tid());\n    }\n\n    // Lock order: session table -> group table -> process table -> group of process\n    // -> group inner -> session inner\n    let mut session_table_mut = process_table::session_table_mut();\n    let mut group_table_mut = process_table::group_table_mut();\n    let mut process_table_mut = process_table::process_table_mut();\n\n    let mut child_group_mut = child_process.process_group.lock();\n\n    let process_group = child_group_mut.upgrade().unwrap();\n    let mut group_inner = process_group.inner.lock();\n    let session = group_inner.session.upgrade().unwrap();\n    let mut session_inner = session.inner.lock();\n\n    group_inner.remove_process(&child_process.pid());\n    session_inner.remove_process(&child_process);\n    *child_group_mut = Weak::new();\n\n    if group_inner.is_empty() {\n        group_table_mut.remove(&process_group.pgid());\n        session_inner.remove_process_group(&process_group.pgid());\n\n        if session_inner.is_empty() {\n            session_table_mut.remove(&session.sid());\n        }\n    }\n\n    process_table_mut.remove(&child_process.pid());\n    child_process.exit_code()\n}\npub fn sys_exit(exit_code: i32, _ctx: &Context) -> Result<SyscallReturn> {\n    debug!(\"exid code = {}\", exit_code);\n\n    let current_thread = current_thread!();\n    let term_status = TermStatus::Exited(exit_code as _);\n    do_exit(current_thread, term_status)?;\n\n    Ok(SyscallReturn::Return(0))\n}\npub fn sys_futex(\n    futex_addr: Vaddr,\n    futex_op: i32,\n    futex_val: u32,\n    utime_addr: u64,\n    futex_new_addr: u64,\n    bitset: u64,\n    ctx: &Context,\n) -> Result<SyscallReturn> {\n    // FIXME: we current ignore futex flags\n    let (futex_op, futex_flags) = futex_op_and_flags_from_u32(futex_op as _)?;\n    debug!(\n        \"futex_op = {:?}, futex_flags = {:?}, futex_addr = 0x{:x}\",\n        futex_op, futex_flags, futex_addr\n    );\n\n    let get_futex_val = |val: i32| -> Result<usize> {\n        if val < 0 {\n            return_errno_with_message!(Errno::EINVAL, \"the futex val must not be negative\");\n        }\n        Ok(val as usize)\n    };\n\n    let get_futex_timeout = |timeout_addr| -> Result<Option<FutexTimeout>> {\n        if timeout_addr == 0 {\n            return Ok(None);\n        }\n        // TODO: parse a timeout\n        todo!()\n    };\n\n    let res = match futex_op {\n        FutexOp::FUTEX_WAIT => {\n            let timeout = get_futex_timeout(utime_addr)?;\n            futex_wait(futex_addr as _, futex_val as _, &timeout).map(|_| 0)\n        }\n        FutexOp::FUTEX_WAIT_BITSET => {\n            let timeout = get_futex_timeout(utime_addr)?;\n            futex_wait_bitset(futex_addr as _, futex_val as _, &timeout, bitset as _).map(|_| 0)\n        }\n        FutexOp::FUTEX_WAKE => {\n            let max_count = get_futex_val(futex_val as i32)?;\n            futex_wake(futex_addr as _, max_count).map(|count| count as isize)\n        }\n        FutexOp::FUTEX_WAKE_BITSET => {\n            let max_count = get_futex_val(futex_val as i32)?;\n            futex_wake_bitset(futex_addr as _, max_count, bitset as _).map(|count| count as isize)\n        }\n        FutexOp::FUTEX_REQUEUE => {\n            let max_nwakes = get_futex_val(futex_val as i32)?;\n            let max_nrequeues = get_futex_val(utime_addr as i32)?;\n            futex_requeue(\n                futex_addr as _,\n                max_nwakes,\n                max_nrequeues,\n                futex_new_addr as _,\n            )\n            .map(|nwakes| nwakes as _)\n        }\n        _ => panic!(\"Unsupported futex operations\"),\n    }?;\n\n    debug!(\"futex returns, tid= {} \", ctx.thread.tid());\n    Ok(SyscallReturn::Return(res as _))\n}\npub fn sys_gettid(ctx: &Context) -> Result<SyscallReturn> {\n    let tid = ctx.thread.tid();\n    Ok(SyscallReturn::Return(tid as _))\n}\npub fn sys_set_tid_address(tidptr: Vaddr, ctx: &Context) -> Result<SyscallReturn> {\n    debug!(\"tidptr = 0x{:x}\", tidptr);\n    let mut clear_child_tid = ctx.posix_thread.clear_child_tid().lock();\n    if *clear_child_tid != 0 {\n        // According to manuals at https://man7.org/linux/man-pages/man2/set_tid_address.2.html\n        // We need to write 0 to clear_child_tid and do futex wake\n        todo!()\n    } else {\n        *clear_child_tid = tidptr;\n    }\n    let tid = ctx.thread.tid();\n    Ok(SyscallReturn::Return(tid as _))\n}\n    fn join(&self) {\n        loop {\n            if self.status().is_exited() {\n                return;\n            } else {\n                Thread::yield_now();\n            }\n        }\n    }\n    pub fn data(&self) -> &Box<dyn Send + Sync + Any> {\n        &self.data\n    }\npub fn allocate_tid() -> Tid {\n    TID_ALLOCATOR.fetch_add(1, Ordering::SeqCst)\n}\n    fn user_task_entry() {\n        let current_thread = current_thread!();\n        let current_posix_thread = current_thread.as_posix_thread().unwrap();\n        let current_process = current_posix_thread.process();\n        let current_task = current_thread.task();\n\n        let user_space = current_task\n            .user_space()\n            .expect(\"user task should have user space\");\n        let mut user_mode = UserMode::new(user_space);\n        debug!(\n            \"[Task entry] rip = 0x{:x}\",\n            user_mode.context().instruction_pointer()\n        );\n        debug!(\n            \"[Task entry] rsp = 0x{:x}\",\n            user_mode.context().stack_pointer()\n        );\n        debug!(\n            \"[Task entry] rax = 0x{:x}\",\n            user_mode.context().syscall_ret()\n        );\n\n        let child_tid_ptr = *current_posix_thread.set_child_tid().lock();\n\n        // The `clone` syscall may require child process to write the thread pid to the specified address.\n        // Make sure the store operation completes before the clone call returns control to user space\n        // in the child process.\n        if is_userspace_vaddr(child_tid_ptr) {\n            CurrentUserSpace::get()\n                .write_val(child_tid_ptr, &current_thread.tid())\n                .unwrap();\n        }\n\n        let has_kernel_event_fn = || current_posix_thread.has_pending();\n\n        let ctx = Context {\n            process: current_process.as_ref(),\n            posix_thread: current_posix_thread,\n            thread: current_thread.as_ref(),\n            task: current_task.as_ref(),\n        };\n\n        loop {\n            let return_reason = user_mode.execute(has_kernel_event_fn);\n            let user_ctx = user_mode.context_mut();\n            // handle user event:\n            match return_reason {\n                ReturnReason::UserException => handle_exception(&ctx, user_ctx),\n                ReturnReason::UserSyscall => handle_syscall(&ctx, user_ctx),\n                ReturnReason::KernelEvent => {}\n            };\n\n            if current_thread.status().is_exited() {\n                break;\n            }\n            handle_pending_signal(user_ctx, &current_thread).unwrap();\n            // If current is suspended, wait for a signal to wake up self\n            while current_thread.status().is_stopped() {\n                Thread::yield_now();\n                debug!(\"{} is suspended.\", current_thread.tid());\n                handle_pending_signal(user_ctx, &current_thread).unwrap();\n            }\n            if current_thread.status().is_exited() {\n                debug!(\"exit due to signal\");\n                break;\n            }\n        }\n        debug!(\"exit user loop\");\n    }\npub fn add_thread(thread: Arc<Thread>) {\n    let tid = thread.tid();\n    THREAD_TABLE.lock().insert(tid, thread);\n}\npub fn remove_thread(tid: Tid) {\n    THREAD_TABLE.lock().remove(&tid);\n}\npub fn get_thread(tid: Tid) -> Option<Arc<Thread>> {\n    THREAD_TABLE.lock().get(&tid).cloned()\n}\n    fn run_worker_loop(self: &Arc<Self>) {\n        loop {\n            let worker_pool = self.worker_pool.upgrade();\n            let Some(worker_pool) = worker_pool else {\n                break;\n            };\n            if let Some(work_item) = worker_pool.fetch_pending_work_item(self.bound_cpu) {\n                work_item.set_processing();\n                work_item.call_work_func();\n                worker_pool.set_heartbeat(self.bound_cpu, true);\n            } else {\n                if self.is_destroying() {\n                    break;\n                }\n                self.inner.disable_irq().lock().worker_status = WorkerStatus::Idle;\n                worker_pool.idle_current_worker(self.bound_cpu, self.clone());\n                if !self.is_destroying() {\n                    self.inner.disable_irq().lock().worker_status = WorkerStatus::Running;\n                }\n            }\n        }\n        self.exit();\n    }\n    pub(super) fn bound_thread(&self) -> &Arc<Thread> {\n        &self.bound_thread\n    }\n    pub(super) fn is_idle(&self) -> bool {\n        self.inner.disable_irq().lock().worker_status == WorkerStatus::Idle\n    }\n    pub fn new(worker_pool: Weak<WorkerPool>, priority: &WorkPriority) -> Arc<Self> {\n        Arc::new_cyclic(|monitor_ref| {\n            let weal_monitor = monitor_ref.clone();\n            let task_fn = Box::new(move || {\n                let current_monitor: Arc<Monitor> = weal_monitor.upgrade().unwrap();\n                current_monitor.run_monitor_loop();\n            });\n            let cpu_affinity = CpuSet::new_full();\n            let priority = match priority {\n                WorkPriority::High => Priority::high(),\n                WorkPriority::Normal => Priority::normal(),\n            };\n            let bound_thread = Thread::new_kernel_thread(\n                ThreadOptions::new(task_fn)\n                    .cpu_affinity(cpu_affinity)\n                    .priority(priority),\n            );\n            Self {\n                worker_pool,\n                bound_thread,\n            }\n        })\n    }\n    pub fn run(&self) {\n        self.bound_thread.run();\n    }\n    fn run_monitor_loop(self: &Arc<Self>) {\n        let sleep_queue = WaitQueue::new();\n        let sleep_duration = Duration::from_millis(100);\n        loop {\n            let worker_pool = self.worker_pool.upgrade();\n            let Some(worker_pool) = worker_pool else {\n                break;\n            };\n            worker_pool.schedule();\n            for local_pool in worker_pool.local_pools.iter() {\n                local_pool.set_heartbeat(false);\n            }\n            let _ = sleep_queue.wait_until_or_timeout(|| -> Option<()> { None }, &sleep_duration);\n        }\n    }\n    pub fn build(self) -> Result<Arc<Task>> {\n        /// all task will entering this function\n        /// this function is mean to executing the task_fn in Task\n        extern \"C\" fn kernel_task_entry() {\n            let current_task = current_task()\n                .expect(\"no current task, it should have current task in kernel task entry\");\n            current_task.func.call(());\n            current_task.exit();\n        }\n\n        let mut new_task = Task {\n            func: self.func.unwrap(),\n            data: self.data.unwrap(),\n            user_space: self.user_space,\n            ctx: UnsafeCell::new(TaskContext::default()),\n            kstack: KernelStack::new_with_guard_page()?,\n            schedule_info: TaskScheduleInfo {\n                cpu: AtomicCpuId::default(),\n                priority: self.priority,\n                cpu_affinity: self.cpu_affinity,\n            },\n        };\n\n        let ctx = new_task.ctx.get_mut();\n        ctx.set_instruction_pointer(kernel_task_entry as usize);\n        // We should reserve space for the return address in the stack, otherwise\n        // we will write across the page boundary due to the implementation of\n        // the context switch.\n        //\n        // According to the System V AMD64 ABI, the stack pointer should be aligned\n        // to at least 16 bytes. And a larger alignment is needed if larger arguments\n        // are passed to the function. The `kernel_task_entry` function does not\n        // have any arguments, so we only need to align the stack pointer to 16 bytes.\n        ctx.set_stack_pointer(crate::mm::paddr_to_vaddr(new_task.kstack.end_paddr() - 16));\n\n        Ok(Arc::new(new_task))\n    }\n    pub fn spawn(self) -> Result<Arc<Task>> {\n        let task = self.build()?;\n        task.run();\n        Ok(task)\n    }\n",
        "review_type": "function",
        "repo": "asterinas/asterinas",
        "issue_detail": {
            "location": "kernel/src/lib.rs: line: 133-143, kernel/src/process/clone.rs: line: 262-269, kernel/src/process/exit.rs: line: 18-27, kernel/src/process/kill.rs: line: 120-134, kernel/src/process/posix_thread/builder.rs: line: 85-119, kernel/src/process/posix_thread/exit.rs: line: 12-27, kernel/src/process/posix_thread/mod.rs: line: 292-295, kernel/src/process/posix_thread/posix_thread_ext.rs: line: 13-65, kernel/src/process/process/builder.rs: line: 206-213, kernel/src/process/process/mod.rs: line: 644-651, kernel/src/process/signal/pause.rs: line: 86-102, kernel/src/process/wait.rs: line: 85-93, kernel/src/syscall/clock_gettime.rs: line: 7-15, kernel/src/syscall/exit.rs: line: 6-18, kernel/src/syscall/futex.rs: line: 71-77, kernel/src/syscall/gettid.rs: line: 4-10, kernel/src/syscall/mod.rs: line: 345-352, kernel/src/syscall/set_tid_address.rs: line: 13-19, kernel/src/syscall/timer_create.rs: line: 17-27, kernel/src/thread/kernel_thread.rs: line: 67-73, kernel/src/thread/mod.rs: line: 106-114, kernel/src/thread/task.rs: line: 77-84, kernel/src/thread/thread_table.rs: line: 1-22, kernel/src/thread/work_queue/worker.rs: line: 97-105, kernel/src/thread/work_queue/worker_pool.rs: line: 236-256, ostd/src/task/mod.rs: line: 201-213, ",
            "description": "Reachable unwrap panic in `read_clock()`\n### Describe the bug\r\nThere is a reachable unwrap panic in `read_clock()` at kernel/src/syscall/clock_gettime.rs:141 when make a `clock_gettime` syscall with specific argument.\r\n\r\nhttps://github.com/asterinas/asterinas/blob/aa77747f94c4b1cb1237ba52414642827a6efc25/kernel/src/syscall/clock_gettime.rs#L141\r\n\r\n\r\n### To Reproduce\r\n1. Compile a program which calls `clock_gettime`:\r\n```C\r\n#include <errno.h>\r\n#include <stdio.h>\r\n#include <sys/syscall.h>\r\n#include <time.h>\r\n#include <unistd.h>\r\n\r\nint main() {\r\n  clock_gettime(-10, 0x1);\r\n  perror(\"clock_gettime\");\r\n\r\n  return 0;\r\n}\r\n```\r\n2. Run the compiled program in Asterinas.\r\n\r\n### Expected behavior\r\nAsterinas reports panic and is terminated.\r\n\r\n### Environment\r\n- Official docker asterinas/asterinas:0.8.0\r\n- 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz\r\n- Asterinas version: main aa77747f\r\n\r\n### Logs\r\n\r\n```\r\n~ # /root/clock_gettime.c \r\npanicked at /root/asterinas/kernel/src/syscall/clock_gettime.rs:141:61:\r\ncalled `Option::unwrap()` on a `None` value\r\nPrinting stack trace:\r\n   1: fn 0xffffffff8880e1c0 - pc 0xffffffff8880e1d8 / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f6297c0;\r\n\r\n   2: fn 0xffffffff8880dfa0 - pc 0xffffffff8880e118 / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f6297d0;\r\n\r\n   3: fn 0xffffffff88049000 - pc 0xffffffff8804900a / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f629950;\r\n\r\n   4: fn 0xffffffff889b0fb0 - pc 0xffffffff889b1032 / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f629960;\r\n\r\n   5: fn 0xffffffff889b1150 - pc 0xffffffff889b1190 / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f6299f0;\r\n\r\n   6: fn 0xffffffff8899a710 - pc 0xffffffff8899a725 / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f629a60;\r\n\r\n   7: fn 0xffffffff884f2290 - pc 0xffffffff884f289f / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f629a70;\r\n\r\n   8: fn 0xffffffff884f1d20 - pc 0xffffffff884f1d81 / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f629d30;\r\n\r\n   9: fn 0xffffffff88161a50 - pc 0xffffffff8818d4ab / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f629f30;\r\n\r\n  10: fn 0xffffffff88152f60 - pc 0xffffffff88152fee / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f6403d0;\r\n\r\n  11: fn 0xffffffff88110380 - pc 0xffffffff88110eff / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f640570;\r\n\r\n  12: fn 0xffffffff8845cb70 - pc 0xffffffff8845cb7e / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f640f90;\r\n\r\n  13: fn 0xffffffff887cdc50 - pc 0xffffffff887cdc66 / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f640fb0;\r\n\r\n  14: fn 0xffffffff887b0280 - pc 0xffffffff887b02e9 / registers:\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f640fd0;\r\n\r\n\r\n     rax               0x12; rdx 0xffffffff88a3a1a0; rcx                0x1; rbx                0x0;\r\n     rsi                0x0; rdi                0x0; rbp                0x0; rsp 0xffff80007f641000;\r\n\r\n[OSDK] The kernel seems panicked. Parsing stack trace for source lines:\r\n(  1) /root/asterinas/ostd/src/panicking.rs:106\r\n(  2) /root/asterinas/ostd/src/panicking.rs:59\r\n(  3) 89yvfinwjerz0clyodmhm6lzz:?\r\n(  4) ??:?\r\n(  5) /root/.rustup/toolchains/nightly-2024-06-20-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/panicking.rs:220\r\n(  6) ??:?\r\n(  7) /root/.rustup/toolchains/nightly-2024-06-20-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/option.rs:961\r\n(  8) /root/asterinas/kernel/src/syscall/clock_gettime.rs:29\r\n(  9) /root/asterinas/kernel/src/syscall/mod.rs:164\r\n( 10) /root/asterinas/kernel/src/syscall/mod.rs:328\r\n( 11) /root/asterinas/kernel/src/thread/task.rs:69\r\n( 12) /root/.rustup/toolchains/nightly-2024-06-20-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/ops/function.rs:79\r\n( 13) /root/.rustup/toolchains/nightly-2024-06-20-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/alloc/src/boxed.rs:2077\r\n( 14) /root/asterinas/ostd/src/task/task/mod.rs:341\r\nmake: *** [Makefile:167: run] Error 1\r\n```\n"
        },
        "branch": "fix-thread-table",
        "file_path": "kernel/src/lib.rs,kernel/src/process/clone.rs,kernel/src/process/clone.rs,kernel/src/process/clone.rs,kernel/src/process/clone.rs,kernel/src/process/clone.rs,kernel/src/process/clone.rs,kernel/src/process/clone.rs,kernel/src/process/exit.rs,kernel/src/process/exit.rs,kernel/src/process/kill.rs,kernel/src/process/kill.rs,kernel/src/process/kill.rs,kernel/src/process/posix_thread/builder.rs,kernel/src/process/posix_thread/builder.rs,kernel/src/process/posix_thread/builder.rs,kernel/src/process/posix_thread/builder.rs,kernel/src/process/posix_thread/exit.rs,kernel/src/process/posix_thread/exit.rs,kernel/src/process/posix_thread/mod.rs,kernel/src/process/posix_thread/mod.rs,kernel/src/process/posix_thread/mod.rs,kernel/src/process/posix_thread/mod.rs,kernel/src/process/posix_thread/mod.rs,kernel/src/process/posix_thread/mod.rs,kernel/src/process/posix_thread/posix_thread_ext.rs,kernel/src/process/posix_thread/posix_thread_ext.rs,kernel/src/process/process/builder.rs,kernel/src/process/process/builder.rs,kernel/src/process/process/builder.rs,kernel/src/process/process/mod.rs,kernel/src/process/process/mod.rs,kernel/src/process/process/mod.rs,kernel/src/process/process/mod.rs,kernel/src/process/process/mod.rs,kernel/src/process/process/mod.rs,kernel/src/process/process/mod.rs,kernel/src/process/process/mod.rs,kernel/src/process/process/mod.rs,kernel/src/process/process/mod.rs,kernel/src/process/process/mod.rs,kernel/src/process/signal/pause.rs,kernel/src/process/wait.rs,kernel/src/process/wait.rs,kernel/src/syscall/clock_gettime.rs,kernel/src/syscall/exit.rs,kernel/src/syscall/futex.rs,kernel/src/syscall/gettid.rs,kernel/src/syscall/mod.rs,kernel/src/syscall/set_tid_address.rs,kernel/src/syscall/timer_create.rs,kernel/src/syscall/timer_create.rs,kernel/src/thread/kernel_thread.rs,kernel/src/thread/kernel_thread.rs,kernel/src/thread/kernel_thread.rs,kernel/src/thread/mod.rs,kernel/src/thread/mod.rs,kernel/src/thread/mod.rs,kernel/src/thread/mod.rs,kernel/src/thread/mod.rs,kernel/src/thread/mod.rs,kernel/src/thread/task.rs,kernel/src/thread/task.rs,kernel/src/thread/task.rs,kernel/src/thread/thread_table.rs,kernel/src/thread/work_queue/worker.rs,kernel/src/thread/work_queue/worker.rs,kernel/src/thread/work_queue/worker.rs,kernel/src/thread/work_queue/worker.rs,kernel/src/thread/work_queue/worker.rs,kernel/src/thread/work_queue/worker_pool.rs,kernel/src/thread/work_queue/worker_pool.rs,kernel/src/thread/work_queue/worker_pool.rs,kernel/src/thread/work_queue/worker_pool.rs,ostd/src/task/mod.rs,ostd/src/task/mod.rs",
        "language": "rust"
    },
    {
        "instance_id": "apache__arrow-rs-4351",
        "code_snippet": "    async fn get_opts(&self, location: &Path, options: GetOptions) -> Result<GetResult>;\n\n    /// Return the bytes that are stored at the specified location\n    /// in the given byte range\n    async fn get_range(&self, location: &Path, range: Range<usize>) -> Result<Bytes> {\n        let options = GetOptions {\n            range: Some(range),\n            ..Default::default()\n        };\n        self.get_opts(location, options).await?.bytes().await\n    }\n    fn poll_shutdown(\n        mut self: Pin<&mut Self>,\n        cx: &mut std::task::Context<'_>,\n    ) -> std::task::Poll<Result<(), io::Error>> {\n        if let Ok(runtime) = tokio::runtime::Handle::try_current() {\n            loop {\n                match &mut self.inner_state {\n                    LocalUploadState::Idle(file) => {\n                        // We are moving file into the future, and it will be dropped on it's completion, closing the file.\n                        let file = Arc::clone(file);\n                        self.inner_state = LocalUploadState::ShuttingDown(Box::pin(\n                            runtime.spawn_blocking(move || (*file).sync_all()).map(\n                                move |res| match res {\n                                    Err(err) => {\n                                        Err(io::Error::new(io::ErrorKind::Other, err))\n                                    }\n                                    Ok(res) => res,\n                                },\n                            ),\n                        ));\n                    }\n                    LocalUploadState::ShuttingDown(fut) => match fut.poll_unpin(cx) {\n                        Poll::Ready(res) => {\n                            res?;\n                            let staging_path =\n                                staged_upload_path(&self.dest, &self.multipart_id);\n                            let dest = self.dest.clone();\n                            self.inner_state = LocalUploadState::Committing(Box::pin(\n                                runtime\n                                    .spawn_blocking(move || {\n                                        std::fs::rename(&staging_path, &dest)\n                                    })\n                                    .map(move |res| match res {\n                                        Err(err) => {\n                                            Err(io::Error::new(io::ErrorKind::Other, err))\n                                        }\n                                        Ok(res) => res,\n                                    }),\n                            ));\n                        }\n                        Poll::Pending => {\n                            return Poll::Pending;\n                        }\n                    },\n                    LocalUploadState::Writing(_, _) => {\n                        return Poll::Ready(Err(io::Error::new(\n                            io::ErrorKind::InvalidInput,\n                            \"Tried to commit a file where a write is in progress.\",\n                        )));\n                    }\n                    LocalUploadState::Committing(fut) => match fut.poll_unpin(cx) {\n                        Poll::Ready(res) => {\n                            self.inner_state = LocalUploadState::Complete;\n                            return Poll::Ready(res);\n                        }\n                        Poll::Pending => return Poll::Pending,\n                    },\n                    LocalUploadState::Complete => {\n                        return Poll::Ready(Err(io::Error::new(\n                            io::ErrorKind::Other,\n                            \"Already complete\",\n                        )))\n                    }\n                }\n            }\n        } else {\n            let staging_path = staged_upload_path(&self.dest, &self.multipart_id);\n            match &mut self.inner_state {\n                LocalUploadState::Idle(file) => {\n                    let file = Arc::clone(file);\n                    self.inner_state = LocalUploadState::Complete;\n                    file.sync_all()?;\n                    std::mem::drop(file);\n                    std::fs::rename(staging_path, &self.dest)?;\n                    Poll::Ready(Ok(()))\n                }\n                _ => {\n                    // If we are running on this thread, then only possible states are Idle and Complete.\n                    Poll::Ready(Err(io::Error::new(\n                        io::ErrorKind::Other,\n                        \"Already complete\",\n                    )))\n                }\n            }\n        }\n    }\nfn read_range(file: &mut File, path: &PathBuf, range: Range<usize>) -> Result<Bytes> {\n    let to_read = range.end - range.start;\n    file.seek(SeekFrom::Start(range.start as u64))\n        .context(SeekSnafu { path })?;\n\n    let mut buf = Vec::with_capacity(to_read);\n    let read = file\n        .take(to_read as u64)\n        .read_to_end(&mut buf)\n        .context(UnableToReadBytesSnafu { path })?;\n\n    ensure!(\n        read == to_read,\n        OutOfRangeSnafu {\n            path,\n            expected: to_read,\n            actual: read\n        }\n    );\n    Ok(buf.into())\n}\n",
        "target_function": "    async fn get_opts(&self, location: &Path, options: GetOptions) -> Result<GetResult>;\n\n    /// Return the bytes that are stored at the specified location\n    /// in the given byte range\n    async fn get_range(&self, location: &Path, range: Range<usize>) -> Result<Bytes> {\n        let options = GetOptions {\n            range: Some(range),\n            ..Default::default()\n        };\n        self.get_opts(location, options).await?.bytes().await\n    }\n    fn poll_shutdown(\n        mut self: Pin<&mut Self>,\n        cx: &mut std::task::Context<'_>,\n    ) -> std::task::Poll<Result<(), io::Error>> {\n        if let Ok(runtime) = tokio::runtime::Handle::try_current() {\n            loop {\n                match &mut self.inner_state {\n                    LocalUploadState::Idle(file) => {\n                        // We are moving file into the future, and it will be dropped on it's completion, closing the file.\n                        let file = Arc::clone(file);\n                        self.inner_state = LocalUploadState::ShuttingDown(Box::pin(\n                            runtime.spawn_blocking(move || (*file).sync_all()).map(\n                                move |res| match res {\n                                    Err(err) => {\n                                        Err(io::Error::new(io::ErrorKind::Other, err))\n                                    }\n                                    Ok(res) => res,\n                                },\n                            ),\n                        ));\n                    }\n                    LocalUploadState::ShuttingDown(fut) => match fut.poll_unpin(cx) {\n                        Poll::Ready(res) => {\n                            res?;\n                            let staging_path =\n                                staged_upload_path(&self.dest, &self.multipart_id);\n                            let dest = self.dest.clone();\n                            self.inner_state = LocalUploadState::Committing(Box::pin(\n                                runtime\n                                    .spawn_blocking(move || {\n                                        std::fs::rename(&staging_path, &dest)\n                                    })\n                                    .map(move |res| match res {\n                                        Err(err) => {\n                                            Err(io::Error::new(io::ErrorKind::Other, err))\n                                        }\n                                        Ok(res) => res,\n                                    }),\n                            ));\n                        }\n                        Poll::Pending => {\n                            return Poll::Pending;\n                        }\n                    },\n                    LocalUploadState::Writing(_, _) => {\n                        return Poll::Ready(Err(io::Error::new(\n                            io::ErrorKind::InvalidInput,\n                            \"Tried to commit a file where a write is in progress.\",\n                        )));\n                    }\n                    LocalUploadState::Committing(fut) => match fut.poll_unpin(cx) {\n                        Poll::Ready(res) => {\n                            self.inner_state = LocalUploadState::Complete;\n                            return Poll::Ready(res);\n                        }\n                        Poll::Pending => return Poll::Pending,\n                    },\n                    LocalUploadState::Complete => {\n                        return Poll::Ready(Err(io::Error::new(\n                            io::ErrorKind::Other,\n                            \"Already complete\",\n                        )))\n                    }\n                }\n            }\n        } else {\n            let staging_path = staged_upload_path(&self.dest, &self.multipart_id);\n            match &mut self.inner_state {\n                LocalUploadState::Idle(file) => {\n                    let file = Arc::clone(file);\n                    self.inner_state = LocalUploadState::Complete;\n                    file.sync_all()?;\n                    std::mem::drop(file);\n                    std::fs::rename(staging_path, &self.dest)?;\n                    Poll::Ready(Ok(()))\n                }\n                _ => {\n                    // If we are running on this thread, then only possible states are Idle and Complete.\n                    Poll::Ready(Err(io::Error::new(\n                        io::ErrorKind::Other,\n                        \"Already complete\",\n                    )))\n                }\n            }\n        }\n    }\nfn read_range(file: &mut File, path: &PathBuf, range: Range<usize>) -> Result<Bytes> {\n    let to_read = range.end - range.start;\n    file.seek(SeekFrom::Start(range.start as u64))\n        .context(SeekSnafu { path })?;\n\n    let mut buf = Vec::with_capacity(to_read);\n    let read = file\n        .take(to_read as u64)\n        .read_to_end(&mut buf)\n        .context(UnableToReadBytesSnafu { path })?;\n\n    ensure!(\n        read == to_read,\n        OutOfRangeSnafu {\n            path,\n            expected: to_read,\n            actual: read\n        }\n    );\n    Ok(buf.into())\n}\n",
        "review_type": "function",
        "repo": "apache/arrow-rs",
        "issue_detail": {
            "location": "object_store/src/lib.rs: line: 359-369, object_store/src/local.rs: line: 863-870, ",
            "description": "Default ObjectStore::get_range Doesn't Apply Range to GetResult::File\n**Describe the bug**\r\n<!--\r\nA clear and concise description of what the bug is.\r\n-->\r\n\r\nThe default implementation of `ObjectStore::get_range` added in #4212 incorrectly handles if `GetResult::File` is returned, instead returning the entire byte range. This is incorrect\r\n\r\n**To Reproduce**\r\n<!--\r\nSteps to reproduce the behavior:\r\n-->\r\n\r\n**Expected behavior**\r\n<!--\r\nA clear and concise description of what you expected to happen.\r\n-->\r\n\r\n**Additional context**\r\n<!--\r\nAdd any other context about the problem here.\r\n-->\n"
        },
        "branch": "get-range-file",
        "file_path": "object_store/src/lib.rs,object_store/src/local.rs",
        "language": "rust"
    },
    {
        "instance_id": "bitflags__bitflags-355",
        "code_snippet": "            pub fn bits_mut(&mut self) -> &mut $T {\n                &mut self.0\n            }\n            pub const fn iter(&self) -> $crate::iter::Iter<$PublicBitFlags> {\n                $crate::iter::Iter::__private_const_new(<$PublicBitFlags as $crate::Flags>::FLAGS, $PublicBitFlags::from_bits_retain(self.0), $PublicBitFlags::from_bits_retain(self.0))\n            }\n            pub const fn iter_names(&self) -> $crate::iter::IterNames<$PublicBitFlags> {\n                $crate::iter::IterNames::__private_const_new(<$PublicBitFlags as $crate::Flags>::FLAGS, $PublicBitFlags::from_bits_retain(self.0), $PublicBitFlags::from_bits_retain(self.0))\n            }\n            pub const fn iter_names(&self) -> $crate::iter::IterNames<$PublicBitFlags> {\n                $crate::iter::IterNames::__private_const_new(<$PublicBitFlags as $crate::Flags>::FLAGS, $PublicBitFlags::from_bits_retain(self.bits()), $PublicBitFlags::from_bits_retain(self.bits()))\n            }\n            fn into_iter(self) -> Self::IntoIter {\n                self.iter()\n            }\n",
        "target_function": "            pub fn bits_mut(&mut self) -> &mut $T {\n                &mut self.0\n            }\n            pub const fn iter(&self) -> $crate::iter::Iter<$PublicBitFlags> {\n                $crate::iter::Iter::__private_const_new(<$PublicBitFlags as $crate::Flags>::FLAGS, $PublicBitFlags::from_bits_retain(self.0), $PublicBitFlags::from_bits_retain(self.0))\n            }\n            pub const fn iter_names(&self) -> $crate::iter::IterNames<$PublicBitFlags> {\n                $crate::iter::IterNames::__private_const_new(<$PublicBitFlags as $crate::Flags>::FLAGS, $PublicBitFlags::from_bits_retain(self.0), $PublicBitFlags::from_bits_retain(self.0))\n            }\n            pub const fn iter_names(&self) -> $crate::iter::IterNames<$PublicBitFlags> {\n                $crate::iter::IterNames::__private_const_new(<$PublicBitFlags as $crate::Flags>::FLAGS, $PublicBitFlags::from_bits_retain(self.bits()), $PublicBitFlags::from_bits_retain(self.bits()))\n            }\n            fn into_iter(self) -> Self::IntoIter {\n                self.iter()\n            }\n",
        "review_type": "function",
        "repo": "bitflags/bitflags",
        "issue_detail": {
            "location": "src/example_generated.rs: line: 39-46, src/external.rs: line: 256-267, src/internal.rs: line: 127-145, src/lib.rs: line: 670-677, src/public.rs: line: 283-291, ",
            "description": "Clippy warnings around \"manual implementation of an assign operation\"\nHi.\r\n\r\nI've run into a new clippy lint warnings such as the following:\r\n\r\n> manual implementation of an assign operation\r\n> for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#assign_op_pattern\r\n> `#[warn(clippy::assign_op_pattern)]` on by default\r\n\r\nI'm following the example from the docs page for the use of the macro (more or less, as below). Can you enlighten me as to why this lint notification is appearing here and if there is some way to fix it? I know I can silence the warnings, it's just annoying to see it pop up whenever I run into it.\r\n\r\n```rust\r\nbitflags! {\r\n    pub struct MemoryAccess: u8 {\r\n        /// None.\r\n        const N = 1 << 0;\r\n        /// Public read.\r\n        const R = 1 << 1;\r\n        /// Public write.\r\n        const W = 1 << 2;\r\n        /// Private read.\r\n        const PR = 1 << 3;\r\n        /// Private write.\r\n        const PW = 1 << 4;\r\n        /// Execute.\r\n        const EX = 1 << 5;\r\n    }\r\n}\r\n```\r\n\r\nThanks!\n"
        },
        "branch": "fix/self-in-flags",
        "file_path": "src/example_generated.rs,src/external.rs,src/external.rs,src/external.rs,src/external.rs,src/external.rs,src/external.rs,src/external.rs,src/external.rs,src/external.rs,src/external.rs,src/external.rs,src/external.rs,src/external.rs,src/internal.rs,src/internal.rs,src/internal.rs,src/lib.rs,src/lib.rs,src/lib.rs,src/lib.rs,src/lib.rs,src/public.rs,src/public.rs,src/public.rs,src/public.rs,src/public.rs,src/public.rs",
        "language": "rust"
    },
    {
        "instance_id": "rust-random__rand-1000",
        "code_snippet": "fn dist_iter(b: &mut Bencher) {\n    let mut rng = Pcg64Mcg::from_entropy();\n    let distr = Normal::new(-2.71828, 3.14159).unwrap();\n    let mut iter = distr.sample_iter(&mut rng);\n\n    b.iter(|| {\n        let mut accum = 0.0;\n        for _ in 0..RAND_BENCH_N {\n            accum += iter.next().unwrap();\n        }\n        accum\n    });\n    b.bytes = size_of::<f64>() as u64 * RAND_BENCH_N;\n}\n    fn sample<R: Rng + ?Sized>(&self, rng: &mut R) -> F {\n        let norm: F = rng.sample(StandardNormal);\n        norm * (self.dof / self.chi.sample(rng)).sqrt()\n    }\n    pub fn new(alpha: F, beta: F) -> Result<Beta<F>, BetaError> {\n        Ok(Beta {\n            gamma_a: Gamma::new(alpha, F::one()).map_err(|_| BetaError::AlphaTooSmall)?,\n            gamma_b: Gamma::new(beta, F::one()).map_err(|_| BetaError::BetaTooSmall)?,\n        })\n    }\n    fn sample<R: Rng + ?Sized>(&self, rng: &mut R) -> F {\n        let x = self.gamma_a.sample(rng);\n        let y = self.gamma_b.sample(rng);\n        x / (x + y)\n    }\n    fn test_beta_invalid_dof() {\n        Beta::new(0., 0.).unwrap();\n    }\n",
        "target_function": "fn dist_iter(b: &mut Bencher) {\n    let mut rng = Pcg64Mcg::from_entropy();\n    let distr = Normal::new(-2.71828, 3.14159).unwrap();\n    let mut iter = distr.sample_iter(&mut rng);\n\n    b.iter(|| {\n        let mut accum = 0.0;\n        for _ in 0..RAND_BENCH_N {\n            accum += iter.next().unwrap();\n        }\n        accum\n    });\n    b.bytes = size_of::<f64>() as u64 * RAND_BENCH_N;\n}\n    fn sample<R: Rng + ?Sized>(&self, rng: &mut R) -> F {\n        let norm: F = rng.sample(StandardNormal);\n        norm * (self.dof / self.chi.sample(rng)).sqrt()\n    }\n    pub fn new(alpha: F, beta: F) -> Result<Beta<F>, BetaError> {\n        Ok(Beta {\n            gamma_a: Gamma::new(alpha, F::one()).map_err(|_| BetaError::AlphaTooSmall)?,\n            gamma_b: Gamma::new(beta, F::one()).map_err(|_| BetaError::BetaTooSmall)?,\n        })\n    }\n    fn sample<R: Rng + ?Sized>(&self, rng: &mut R) -> F {\n        let x = self.gamma_a.sample(rng);\n        let y = self.gamma_b.sample(rng);\n        x / (x + y)\n    }\n    fn test_beta_invalid_dof() {\n        Beta::new(0., 0.).unwrap();\n    }\n",
        "review_type": "function",
        "repo": "rust-random/rand",
        "issue_detail": {
            "location": "rand_distr/benches/distributions.rs: line: 20-27, line: 112-123, line: 127-137, rand_distr/src/gamma.rs: line: 495-501, line: 510-522, line: 542-573, line: 636-640, ",
            "description": "Unexpected sample values from beta distribution for small parameters\n## Background\r\n[Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution) is implemented through the [Beta struct](https://rust-random.github.io/rand/rand_distr/struct.Beta.html) and samples should give a number between zero and one. It is known that this distribution is numerically delicate when dealing with both parameters (alpha and beta) small.\r\n\r\nThe implementation of the `sample` method is though the following characterization. \r\nIf X, Y are independent and X follows Gamma(alpha, theta) and Y follows Gamma(beta, theta), then X / (X + Y) follows Beta(alpha, beta).\r\nFor more such characterization, see [here](https://en.wikipedia.org/wiki/Beta_distribution#Derived_from_other_distributions).\r\n\r\nSampling from a beta distribution with both alpha and beta parameters small returns NAN samples. This is clear from the implementation, but is not expected for the user at all!\r\nBy the way, values of `1.0e-3` are already small enough to easily get a NAN result. Just run the following code.\r\n```rust\r\nuse rand::distributions::Distribution;\r\nfn main() {\r\n\tlet param = 1.0e-3;\r\n\tlet beta = rand_distr::Beta::new(param, param).unwrap();\r\n\tfor x in beta.sample_iter(rand::thread_rng()) {\r\n\t\tif (x as f64).is_nan() {\r\n\t\t\tprintln!(\"I got a NAN!!\");\r\n\t\t}\r\n\t}\r\n}\r\n```\r\n\r\n**What is your motivation?**\r\nI as doing numerical simulations and need to simulation beta samples as part of a rejection sampling algorithm. Running into nan values was unexpected, but could solve the issue by a particular symmetry present in my problem.\r\n\r\n**What type of application is this?** (E.g. cryptography, game, numerical simulation)\r\nNumerical simulation.\r\n\r\n## Feature request\r\nI would like to contribute to a more robust simulation method of the beta variable that takes into account such cases.\r\n\r\n<details here>\r\nI don't have a particular idea in mind. \r\nI tried the [scipy module to simulate beta](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html) and it seemed more robust (it gave some numbers that made sense in the cases I tried).\n"
        },
        "branch": "improve-beta",
        "file_path": "rand_distr/benches/distributions.rs,rand_distr/src/gamma.rs",
        "language": "rust"
    },
    {
        "instance_id": "rayon-rs__rayon-986",
        "code_snippet": "    fn drop(&mut self) {\n        if !self.range.is_empty() {\n            let Range { start, end } = self.range;\n            if self.vec.len() != start {\n                // We must not have produced, so just call a normal drain to remove the items.\n                assert_eq!(self.vec.len(), self.orig_len);\n                self.vec.drain(start..end);\n            } else if end < self.orig_len {\n                // The producer was responsible for consuming the drained items.\n                // Move the tail items to their new place, then set the length to include them.\n                unsafe {\n                    let ptr = self.vec.as_mut_ptr().add(start);\n                    let tail_ptr = self.vec.as_ptr().add(end);\n                    let tail_len = self.orig_len - end;\n                    ptr::copy(tail_ptr, ptr, tail_len);\n                    self.vec.set_len(start + tail_len);\n                }\n            }\n        }\n    }\n",
        "target_function": "    fn drop(&mut self) {\n        if !self.range.is_empty() {\n            let Range { start, end } = self.range;\n            if self.vec.len() != start {\n                // We must not have produced, so just call a normal drain to remove the items.\n                assert_eq!(self.vec.len(), self.orig_len);\n                self.vec.drain(start..end);\n            } else if end < self.orig_len {\n                // The producer was responsible for consuming the drained items.\n                // Move the tail items to their new place, then set the length to include them.\n                unsafe {\n                    let ptr = self.vec.as_mut_ptr().add(start);\n                    let tail_ptr = self.vec.as_ptr().add(end);\n                    let tail_len = self.orig_len - end;\n                    ptr::copy(tail_ptr, ptr, tail_len);\n                    self.vec.set_len(start + tail_len);\n                }\n            }\n        }\n    }\n",
        "review_type": "function",
        "repo": "rayon-rs/rayon",
        "issue_detail": {
            "location": "src/vec.rs: line: 151-173, ",
            "description": "Bug in Drop for Drain<'data, T>\nIf you try:\r\n```rust\r\nuse rayon::prelude::*;\r\n\r\nfn main() {\r\n    let mut vec_org = vec![0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\r\n\r\n    let yielded = vec_org.par_drain(5..5).into_par_iter().collect::<Vec<_>>();\r\n\r\n    println!(\"{:?}\", vec_org);\r\n}\r\n\r\n```\r\nit will print a little bit unexpected result:\r\n```\r\n[0, 1, 2, 3, 4]\r\n```\n"
        },
        "branch": "fix_drain_drop_impl",
        "file_path": "src/vec.rs",
        "language": "rust"
    },
    {
        "instance_id": "GuillaumeGomez__sysinfo-367",
        "code_snippet": "    fn refresh_process(&mut self, pid: Pid) -> bool {\n        self.uptime = get_uptime();\n        let found = match _get_process_data(\n            &Path::new(\"/proc/\").join(pid.to_string()),\n            &mut self.process_list,\n            self.page_size_kb,\n            0,\n            self.uptime,\n            get_secs_since_epoch(),\n        ) {\n            Ok((Some(p), pid)) => {\n                self.process_list.tasks.insert(pid, p);\n                false\n            }\n            Ok(_) => true,\n            Err(_) => false,\n        };\n        if found && !self.processors.is_empty() {\n            self.refresh_processors(Some(1));\n            let (new, old) = get_raw_times(&self.global_processor);\n            let total_time = (if old > new { 1 } else { new - old }) as f32;\n\n            if let Some(p) = self.process_list.tasks.get_mut(&pid) {\n                compute_cpu_usage(p, self.processors.len() as u64, total_time);\n            }\n        }\n        found\n    }\npub(crate) fn compute_cpu_usage(p: &mut Process, nb_processors: u64, now: ULARGE_INTEGER) {\n    unsafe {\n        let mut sys: ULARGE_INTEGER = ::std::mem::zeroed();\n        let mut user: ULARGE_INTEGER = ::std::mem::zeroed();\n        let mut ftime: FILETIME = zeroed();\n        let mut fsys: FILETIME = zeroed();\n        let mut fuser: FILETIME = zeroed();\n\n        GetProcessTimes(\n            *p.handle,\n            &mut ftime as *mut FILETIME,\n            &mut ftime as *mut FILETIME,\n            &mut fsys as *mut FILETIME,\n            &mut fuser as *mut FILETIME,\n        );\n        memcpy(\n            &mut sys as *mut ULARGE_INTEGER as *mut c_void,\n            &mut fsys as *mut FILETIME as *mut c_void,\n            size_of::<FILETIME>(),\n        );\n        memcpy(\n            &mut user as *mut ULARGE_INTEGER as *mut c_void,\n            &mut fuser as *mut FILETIME as *mut c_void,\n            size_of::<FILETIME>(),\n        );\n        p.cpu_usage = (check_sub(*sys.QuadPart(), p.old_sys_cpu) as f32\n            + check_sub(*user.QuadPart(), p.old_user_cpu) as f32)\n            / check_sub(*now.QuadPart(), p.old_cpu) as f32\n            / nb_processors as f32\n            * 100.;\n        p.old_cpu = *now.QuadPart();\n        p.old_user_cpu = *user.QuadPart();\n        p.old_sys_cpu = *sys.QuadPart();\n    }\n}\n",
        "target_function": "    fn refresh_process(&mut self, pid: Pid) -> bool {\n        self.uptime = get_uptime();\n        let found = match _get_process_data(\n            &Path::new(\"/proc/\").join(pid.to_string()),\n            &mut self.process_list,\n            self.page_size_kb,\n            0,\n            self.uptime,\n            get_secs_since_epoch(),\n        ) {\n            Ok((Some(p), pid)) => {\n                self.process_list.tasks.insert(pid, p);\n                false\n            }\n            Ok(_) => true,\n            Err(_) => false,\n        };\n        if found && !self.processors.is_empty() {\n            self.refresh_processors(Some(1));\n            let (new, old) = get_raw_times(&self.global_processor);\n            let total_time = (if old > new { 1 } else { new - old }) as f32;\n\n            if let Some(p) = self.process_list.tasks.get_mut(&pid) {\n                compute_cpu_usage(p, self.processors.len() as u64, total_time);\n            }\n        }\n        found\n    }\npub(crate) fn compute_cpu_usage(p: &mut Process, nb_processors: u64, now: ULARGE_INTEGER) {\n    unsafe {\n        let mut sys: ULARGE_INTEGER = ::std::mem::zeroed();\n        let mut user: ULARGE_INTEGER = ::std::mem::zeroed();\n        let mut ftime: FILETIME = zeroed();\n        let mut fsys: FILETIME = zeroed();\n        let mut fuser: FILETIME = zeroed();\n\n        GetProcessTimes(\n            *p.handle,\n            &mut ftime as *mut FILETIME,\n            &mut ftime as *mut FILETIME,\n            &mut fsys as *mut FILETIME,\n            &mut fuser as *mut FILETIME,\n        );\n        memcpy(\n            &mut sys as *mut ULARGE_INTEGER as *mut c_void,\n            &mut fsys as *mut FILETIME as *mut c_void,\n            size_of::<FILETIME>(),\n        );\n        memcpy(\n            &mut user as *mut ULARGE_INTEGER as *mut c_void,\n            &mut fuser as *mut FILETIME as *mut c_void,\n            size_of::<FILETIME>(),\n        );\n        p.cpu_usage = (check_sub(*sys.QuadPart(), p.old_sys_cpu) as f32\n            + check_sub(*user.QuadPart(), p.old_user_cpu) as f32)\n            / check_sub(*now.QuadPart(), p.old_cpu) as f32\n            / nb_processors as f32\n            * 100.;\n        p.old_cpu = *now.QuadPart();\n        p.old_user_cpu = *user.QuadPart();\n        p.old_sys_cpu = *sys.QuadPart();\n    }\n}\n",
        "review_type": "function",
        "repo": "GuillaumeGomez/sysinfo",
        "issue_detail": {
            "location": "src/linux/system.rs: line: 377-384, src/windows/process.rs: line: 739-748, ",
            "description": "Process cpu_usage() returns NaN in some cases\nHello,\r\nI'm using `sysinfo` on version `0.15.2` on Linux mint 19.\r\n`cargo -V` outputs `cargo 1.46.0 (149022b1d 2020-07-17)`.\r\n`rustc -V` outputs `rustc 1.46.0 (04488afe3 2020-08-24)`.\r\n\r\nWhen `system.refresh_process(pid)` is called too often, the cpu_usage() of this process becomes NaN (or sometimes inf).\r\nI have tried to understand where is this comes from, and I think that the bug is in `system.rs`, in the function `refresh_process` (line 380):\r\n```\r\nlet total_time = (if old > new { 1 } else { new - old }) as f32;\r\n```\r\nIf by any chance `new == old`, then `total_time` would be zero. \r\n`total_time` is then sent as an argument to `compute_cpu_usage`, which uses it in the denominator.\r\n\r\nThe code to reproduce:\r\n```\r\nfn main() {\r\n    let mut system: System = System::new();\r\n    system.refresh_processes();\r\n\r\n    let first_5_pids: Vec<Pid> = system.get_processes()\r\n        .iter()\r\n        .take(5)\r\n        .map(|(pid, _)| *pid as Pid)\r\n        .collect::<Vec<Pid>>();\r\n\r\n    first_5_pids.iter().for_each(|pid| {\r\n        system.refresh_process(*pid as Pid);\r\n        let proc = system.get_process(*pid as Pid).unwrap();\r\n        println!(\"pid: {}, cpu: {}\", proc.pid(), proc.cpu_usage());\r\n    });\r\n}\r\n```\r\n\r\nthe output is as follows:\r\n```\r\npid: 673, cpu: 0\r\npid: 1736, cpu: NaN\r\npid: 58, cpu: NaN\r\npid: 684, cpu: NaN\r\npid: 52, cpu: NaN\r\n```\n"
        },
        "branch": "cpu-nan",
        "file_path": "src/linux/system.rs,src/windows/process.rs",
        "language": "rust"
    },
    {
        "instance_id": "crossbeam-rs__crossbeam-1101",
        "code_snippet": "",
        "target_function": "",
        "review_type": "function",
        "repo": "crossbeam-rs/crossbeam",
        "issue_detail": {
            "location": "crossbeam-skiplist/src/base.rs: line: 956-969, ",
            "description": "crossbeam-skiplist bug\n[dependencies]\r\ncrossbeam-skiplist = \"0.1.1\"\r\n\r\n```rs\r\nfn main() {\r\n    let map: Arc<SkipMap<u32, u32>> = Arc::new(SkipMap::new());\r\n    map.insert(1, 2);\r\n    let map1 = map.clone();\r\n    std::thread::spawn(move||{\r\n        let key = 1;\r\n        for _ in 0..10_0000 {\r\n            let len = map1.len();\r\n            if let Some(entry) = map1.get(&key) {\r\n\r\n            }else{\r\n                panic!(\"len={},key={}\",len,key);\r\n            }\r\n            std::thread::sleep(Duration::from_millis(1));\r\n        }\r\n    });\r\n    for _ in 0..10_0000 {\r\n        map.insert(1, 2);\r\n        std::thread::sleep(Duration::from_millis(100));\r\n    }\r\n}\r\n```\r\noutput:\r\n```\r\nthread '<unnamed>' panicked at 'len=1,key=1', src\\main.rs:21:17\r\nstack backtrace:\r\n```\r\n\n"
        },
        "branch": "fix/insert_get_same_key",
        "file_path": "crossbeam-skiplist/src/base.rs,crossbeam-skiplist/src/base.rs,crossbeam-skiplist/src/base.rs",
        "language": "rust"
    },
    {
        "instance_id": "dtolnay__syn-1759",
        "code_snippet": "    pub(crate) fn parse_inner(input: ParseStream, attrs: &mut Vec<Attribute>) -> Result<()> {\n        while input.peek(Token![#]) && input.peek2(Token![!]) {\n            attrs.push(input.call(single_parse_inner)?);\n        }\n        Ok(())\n    }\n        fn parse(input: ParseStream) -> Result<Self> {\n            let path = input.call(Path::parse_mod_style)?;\n            parse_meta_after_path(path, input)\n        }\n        fn parse(input: ParseStream) -> Result<Self> {\n            let path = input.call(Path::parse_mod_style)?;\n            parse_meta_list_after_path(path, input)\n        }\n        fn parse(input: ParseStream) -> Result<Self> {\n            let path = input.call(Path::parse_mod_style)?;\n            parse_meta_name_value_after_path(path, input)\n        }\n    pub(crate) fn parse_meta_after_path(path: Path, input: ParseStream) -> Result<Meta> {\n        if input.peek(token::Paren) || input.peek(token::Bracket) || input.peek(token::Brace) {\n            parse_meta_list_after_path(path, input).map(Meta::List)\n        } else if input.peek(Token![=]) {\n            parse_meta_name_value_after_path(path, input).map(Meta::NameValue)\n        } else {\n            Ok(Meta::Path(path))\n        }\n    }\n",
        "target_function": "    pub(crate) fn parse_inner(input: ParseStream, attrs: &mut Vec<Attribute>) -> Result<()> {\n        while input.peek(Token![#]) && input.peek2(Token![!]) {\n            attrs.push(input.call(single_parse_inner)?);\n        }\n        Ok(())\n    }\n        fn parse(input: ParseStream) -> Result<Self> {\n            let path = input.call(Path::parse_mod_style)?;\n            parse_meta_after_path(path, input)\n        }\n        fn parse(input: ParseStream) -> Result<Self> {\n            let path = input.call(Path::parse_mod_style)?;\n            parse_meta_list_after_path(path, input)\n        }\n        fn parse(input: ParseStream) -> Result<Self> {\n            let path = input.call(Path::parse_mod_style)?;\n            parse_meta_name_value_after_path(path, input)\n        }\n    pub(crate) fn parse_meta_after_path(path: Path, input: ParseStream) -> Result<Meta> {\n        if input.peek(token::Paren) || input.peek(token::Bracket) || input.peek(token::Brace) {\n            parse_meta_list_after_path(path, input).map(Meta::List)\n        } else if input.peek(Token![=]) {\n            parse_meta_name_value_after_path(path, input).map(Meta::NameValue)\n        } else {\n            Ok(Meta::Path(path))\n        }\n    }\n",
        "review_type": "function",
        "repo": "dtolnay/syn",
        "issue_detail": {
            "location": "src/attr.rs: line: 653-659, line: 685-692, line: 693-700, line: 701-712, ",
            "description": "Parse unsafe attributes\n- https://github.com/rust-lang/rust/issues/123757\r\n- https://github.com/rust-lang/rfcs/pull/3325\r\n\r\n```console\r\nerror: expected identifier, found keyword `unsafe`\r\n --> dev/main.rs:4:3\r\n  |\r\n4 | #[unsafe(no_mangle)]\r\n  |   ^^^^^^\r\n```\n"
        },
        "branch": "unsafeattr",
        "file_path": "src/attr.rs",
        "language": "rust"
    },
    {
        "instance_id": "rust-lang__regex-1111",
        "code_snippet": "    fn try_search_half_rev_limited(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        min_start: usize,\n    ) -> Result<Option<HalfMatch>, RetryError> {\n        if let Some(e) = self.core.dfa.get(&input) {\n            trace!(\n                \"using full DFA for reverse suffix search at {:?}, \\\n                 but will be stopped at {} to avoid quadratic behavior\",\n                input.get_span(),\n                min_start,\n            );\n            e.try_search_half_rev_limited(&input, min_start)\n        } else if let Some(e) = self.core.hybrid.get(&input) {\n            trace!(\n                \"using lazy DFA for reverse inner search at {:?}, \\\n                 but will be stopped at {} to avoid quadratic behavior\",\n                input.get_span(),\n                min_start,\n            );\n            e.try_search_half_rev_limited(&mut cache.hybrid, &input, min_start)\n        } else {\n            unreachable!(\"ReverseSuffix always has a DFA\")\n        }\n    }\n",
        "target_function": "    fn try_search_half_rev_limited(\n        &self,\n        cache: &mut Cache,\n        input: &Input<'_>,\n        min_start: usize,\n    ) -> Result<Option<HalfMatch>, RetryError> {\n        if let Some(e) = self.core.dfa.get(&input) {\n            trace!(\n                \"using full DFA for reverse suffix search at {:?}, \\\n                 but will be stopped at {} to avoid quadratic behavior\",\n                input.get_span(),\n                min_start,\n            );\n            e.try_search_half_rev_limited(&input, min_start)\n        } else if let Some(e) = self.core.hybrid.get(&input) {\n            trace!(\n                \"using lazy DFA for reverse inner search at {:?}, \\\n                 but will be stopped at {} to avoid quadratic behavior\",\n                input.get_span(),\n                min_start,\n            );\n            e.try_search_half_rev_limited(&mut cache.hybrid, &input, min_start)\n        } else {\n            unreachable!(\"ReverseSuffix always has a DFA\")\n        }\n    }\n",
        "review_type": "function",
        "repo": "rust-lang/regex",
        "issue_detail": {
            "location": "regex-automata/src/meta/strategy.rs: line: 1268-1275, ",
            "description": "broadening of reverse suffix optimization has led to incorrect matches\nSpecifically, this program succeeds in `regex 1.9.x` but fails in `regex 1.10.1`:\r\n\r\n```rust\r\nfn main() -> anyhow::Result<()> {\r\n    let re = regex::Regex::new(r\"(\\\\N\\{[^}]+})|([{}])\").unwrap();\r\n    let hay = r#\"hiya \\N{snowman} bye\"#;\r\n    let matches = re.find_iter(hay).map(|m| m.range()).collect::<Vec<_>>();\r\n    assert_eq!(matches, vec![5..16]);\r\n    Ok(())\r\n}\r\n```\r\n\r\nIts output with `1.10.1`:\r\n\r\n```\r\n$ cargo run -q\r\nthread 'main' panicked at main.rs:7:5:\r\nassertion `left == right` failed\r\n  left: [7..8, 15..16]\r\n right: [5..16]\r\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\r\n```\r\n\r\nI believe the issue here was my change to broaden the reverse suffix optimization to use one of many possible literals. But this turns out to be not be quite correct since the rules that govern prefixes don't apply to suffixes. In this case, the literal optimization extracts `{` and `}` as suffixes. It looks for a `{` first and finds a match at that position via the second alternate in the regex. But this winds up missing the match that came before it with the first alternate since the `{` isn't a suffix of the first alternate.\r\n\r\nThis is why we should, at least at present, only use this optimization when there is a non-empty longest common suffix. In that case, and only that case, we know that it is a suffix of every possible path through the regex.\r\n\r\nThank you to @charliermarsh for finding this! See: https://github.com/astral-sh/ruff/pull/7980\n"
        },
        "branch": "ag/fix-reverse-suffix",
        "file_path": "regex-automata/src/meta/strategy.rs,regex-automata/src/meta/strategy.rs",
        "language": "rust"
    }
]